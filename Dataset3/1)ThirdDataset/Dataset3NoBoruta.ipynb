{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13719, 16)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np # linear algebra\n",
    "\n",
    "# Replace 'path_to_dataset' with the actual path to your dataset file\n",
    "df = pd.read_csv('Dataset33new (1).csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['Brand'])\n",
    "y = df['Brand']\n",
    "\n",
    "categorical_columns = X.select_dtypes(include=['object']).columns\n",
    "numerical_columns = X.select_dtypes(include=['int', 'float']).columns\n",
    "\n",
    "# Create DataFrames for categorical and numerical columns\n",
    "X_categorical = X[categorical_columns]\n",
    "X_numerical = X[numerical_columns]\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "\n",
    "# Perform label encoding only on columns with dtype object\n",
    "label_encoder = LabelEncoder()\n",
    "X_encoded = X_categorical.copy()\n",
    "for col in categorical_columns:\n",
    "    X_encoded[col] = X[col].astype(str)  # Ensure the column is of string dtype before label encoding\n",
    "    X_encoded[col] = label_encoder.fit_transform(X_encoded[col])\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "\n",
    "# Initialize LabelEncoder for the target variable y\n",
    "label_encoder_y = LabelEncoder()\n",
    "y_encoded = label_encoder_y.fit_transform(y)\n",
    "# Merge with original X containing int and float columns\n",
    "X_final = pd.concat([X_encoded, X.select_dtypes(include=['int', 'float'])], axis=1)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_final, y_encoded, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled_smote, y_train_resampled_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "borderline_smote = BorderlineSMOTE(random_state=42)\n",
    "X_train_resampled_borderline, y_train_resampled_borderline = borderline_smote.fit_resample(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMOTE + Bordeline SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Best Parameters: {'max_depth': None, 'n_estimators': 200}\n",
      "Accuracy (Best Random Forest with SMOTE): 0.9566326530612245\n",
      "Classification Report (Best Random Forest with SMOTE):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0      0.880     0.973     0.924        75\n",
      "           1      0.933     0.933     0.933        60\n",
      "           2      0.955     0.929     0.942       182\n",
      "           3      0.973     0.973     0.973        37\n",
      "           4      0.945     0.972     0.958       212\n",
      "           5      0.922     0.922     0.922        77\n",
      "           6      0.966     0.927     0.947       248\n",
      "           7      1.000     1.000     1.000        41\n",
      "           8      0.891     0.983     0.934        58\n",
      "           9      0.929     0.940     0.935       167\n",
      "          10      1.000     1.000     1.000        43\n",
      "          11      0.880     0.786     0.830        28\n",
      "          12      1.000     1.000     1.000        66\n",
      "          13      0.986     0.982     0.984       223\n",
      "          14      0.952     0.884     0.917       112\n",
      "          15      0.964     0.964     0.964       194\n",
      "          16      0.977     0.949     0.963       178\n",
      "          17      0.923     0.923     0.923        26\n",
      "          18      0.871     0.990     0.927       102\n",
      "          19      1.000     0.959     0.979        49\n",
      "          20      0.983     0.985     0.984       410\n",
      "          21      0.967     0.949     0.958       156\n",
      "\n",
      "    accuracy                          0.957      2744\n",
      "   macro avg      0.950     0.951     0.950      2744\n",
      "weighted avg      0.958     0.957     0.957      2744\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "\n",
    "# Initialize the Random Forest classifier\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Train the classifier\n",
    "rf_classifier.fit(X_train_resampled_smote, y_train_resampled_smote)\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'max_depth': [2, 3, 4, 5, None],\n",
    "    'n_estimators': [50, 100, 150, 200],\n",
    "}\n",
    "\n",
    "# Initialize the Random Forest classifier\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=rf_classifier,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,  # 5-fold cross-validation\n",
    "    verbose=2,\n",
    "    n_jobs=-1  # Use all available cores\n",
    ")\n",
    "\n",
    "# Fit GridSearchCV\n",
    "grid_search.fit(X_train_resampled_smote, y_train_resampled_smote)\n",
    "\n",
    "# Get the best model\n",
    "best_rf_classifier = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on the test set using the best model\n",
    "y_pred_best_rf = best_rf_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the best model\n",
    "accuracy_best_rf = accuracy_score(y_test, y_pred_best_rf)\n",
    "classification_report_result_best_rf = classification_report(y_test, y_pred_best_rf, digits=3)\n",
    "\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "print(f\"Accuracy (Best Random Forest with SMOTE): {accuracy_best_rf}\")\n",
    "print(\"Classification Report (Best Random Forest with SMOTE):\\n\", classification_report_result_best_rf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Best Parameters: {'max_depth': None, 'n_estimators': 200}\n",
      "Accuracy (Best Random Forest with Borderline SMOTE): 0.9504373177842566\n",
      "Classification Report (Best Random Forest with Borderline SMOTE):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0      0.877     0.947     0.910        75\n",
      "           1      0.933     0.933     0.933        60\n",
      "           2      0.960     0.912     0.935       182\n",
      "           3      1.000     0.973     0.986        37\n",
      "           4      0.923     0.967     0.945       212\n",
      "           5      0.883     0.883     0.883        77\n",
      "           6      0.951     0.931     0.941       248\n",
      "           7      1.000     0.951     0.975        41\n",
      "           8      0.889     0.966     0.926        58\n",
      "           9      0.945     0.928     0.937       167\n",
      "          10      1.000     1.000     1.000        43\n",
      "          11      0.909     0.714     0.800        28\n",
      "          12      1.000     0.985     0.992        66\n",
      "          13      0.978     0.987     0.982       223\n",
      "          14      0.944     0.902     0.922       112\n",
      "          15      0.944     0.959     0.951       194\n",
      "          16      0.956     0.966     0.961       178\n",
      "          17      0.957     0.846     0.898        26\n",
      "          18      0.885     0.980     0.930       102\n",
      "          19      1.000     0.939     0.968        49\n",
      "          20      0.980     0.980     0.980       410\n",
      "          21      0.955     0.949     0.952       156\n",
      "\n",
      "    accuracy                          0.950      2744\n",
      "   macro avg      0.949     0.936     0.941      2744\n",
      "weighted avg      0.951     0.950     0.950      2744\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Initialize Borderline SMOTE\n",
    "\n",
    "# Define the parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'max_depth': [2, 3, 4, 5, None],\n",
    "    'n_estimators': [50, 100, 150, 200],\n",
    "}\n",
    "\n",
    "# Initialize the Random Forest classifier\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=rf_classifier,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,  # 5-fold cross-validation\n",
    "    verbose=2,\n",
    "    n_jobs=-1  # Use all available cores\n",
    ")\n",
    "\n",
    "# Fit GridSearchCV with resampled data\n",
    "grid_search.fit(X_train_resampled_borderline, y_train_resampled_borderline)\n",
    "\n",
    "# Get the best model\n",
    "best_rf_classifier = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on the test set using the best model\n",
    "y_pred_best_rf = best_rf_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the best model\n",
    "accuracy_best_rf = accuracy_score(y_test, y_pred_best_rf)\n",
    "classification_report_result_best_rf = classification_report(y_test, y_pred_best_rf, digits=3)\n",
    "\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "print(f\"Accuracy (Best Random Forest with Borderline SMOTE): {accuracy_best_rf}\")\n",
    "print(\"Classification Report (Best Random Forest with Borderline SMOTE):\\n\", classification_report_result_best_rf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gaussian NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Best Parameters: {'var_smoothing': 1e-09}\n",
      "Accuracy (Best GaussianNB with SMOTE): 0.22631195335276968\n",
      "Classification Report (Best GaussianNB with SMOTE):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0      0.800     0.053     0.100        75\n",
      "           1      0.500     0.033     0.062        60\n",
      "           2      0.551     0.236     0.331       182\n",
      "           3      0.342     0.703     0.460        37\n",
      "           4      0.358     0.325     0.341       212\n",
      "           5      0.078     0.662     0.140        77\n",
      "           6      0.278     0.020     0.038       248\n",
      "           7      0.173     1.000     0.295        41\n",
      "           8      0.422     0.655     0.514        58\n",
      "           9      0.085     0.084     0.084       167\n",
      "          10      1.000     0.860     0.925        43\n",
      "          11      0.135     0.250     0.175        28\n",
      "          12      0.269     0.682     0.386        66\n",
      "          13      0.585     0.108     0.182       223\n",
      "          14      0.229     0.214     0.221       112\n",
      "          15      0.213     0.253     0.231       194\n",
      "          16      0.338     0.129     0.187       178\n",
      "          17      0.087     0.154     0.111        26\n",
      "          18      0.390     0.471     0.427       102\n",
      "          19      0.080     0.245     0.121        49\n",
      "          20      0.259     0.124     0.168       410\n",
      "          21      0.364     0.026     0.048       156\n",
      "\n",
      "    accuracy                          0.226      2744\n",
      "   macro avg      0.343     0.331     0.252      2744\n",
      "weighted avg      0.339     0.226     0.211      2744\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'var_smoothing': [1e-9, 1.778e-7, 3.162e-5, 5.6e-3, 1]\n",
    "}\n",
    "\n",
    "# Initialize the GaussianNB classifier\n",
    "gnb_classifier = GaussianNB()\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=gnb_classifier,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,  # 5-fold cross-validation\n",
    "    verbose=2,\n",
    "    n_jobs=-1  # Use all available cores\n",
    ")\n",
    "\n",
    "# Fit GridSearchCV\n",
    "grid_search.fit(X_train_resampled_smote, y_train_resampled_smote)\n",
    "\n",
    "# Get the best model\n",
    "best_gnb_classifier = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on the test set using the best model\n",
    "y_pred_best_gnb = best_gnb_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the best model\n",
    "accuracy_best_gnb = accuracy_score(y_test, y_pred_best_gnb)\n",
    "classification_report_result_best_gnb = classification_report(y_test, y_pred_best_gnb, digits=3)\n",
    "\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "print(f\"Accuracy (Best GaussianNB with SMOTE): {accuracy_best_gnb}\")\n",
    "print(\"Classification Report (Best GaussianNB with SMOTE):\\n\", classification_report_result_best_gnb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Best Parameters: {'var_smoothing': 1e-09}\n",
      "Accuracy (Best GaussianNB with SMOTE): 0.23287172011661808\n",
      "Classification Report (Best GaussianNB with SMOTE):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0      0.500     0.027     0.051        75\n",
      "           1      0.231     0.050     0.082        60\n",
      "           2      0.500     0.269     0.350       182\n",
      "           3      0.308     0.757     0.438        37\n",
      "           4      0.362     0.297     0.326       212\n",
      "           5      0.080     0.623     0.142        77\n",
      "           6      0.231     0.036     0.063       248\n",
      "           7      0.191     0.927     0.317        41\n",
      "           8      0.414     0.621     0.497        58\n",
      "           9      0.087     0.084     0.086       167\n",
      "          10      1.000     0.837     0.911        43\n",
      "          11      0.074     0.143     0.098        28\n",
      "          12      0.392     0.576     0.466        66\n",
      "          13      0.568     0.112     0.187       223\n",
      "          14      0.188     0.277     0.224       112\n",
      "          15      0.207     0.268     0.234       194\n",
      "          16      0.329     0.135     0.191       178\n",
      "          17      0.123     0.269     0.169        26\n",
      "          18      0.407     0.471     0.436       102\n",
      "          19      0.094     0.286     0.141        49\n",
      "          20      0.296     0.166     0.212       410\n",
      "          21      0.286     0.013     0.025       156\n",
      "\n",
      "    accuracy                          0.233      2744\n",
      "   macro avg      0.312     0.329     0.257      2744\n",
      "weighted avg      0.318     0.233     0.221      2744\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'var_smoothing': [1e-9, 1.778e-7, 3.162e-5, 5.6e-3, 1]\n",
    "}\n",
    "\n",
    "# Initialize the GaussianNB classifier\n",
    "gnb_classifier = GaussianNB()\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=gnb_classifier,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,  # 5-fold cross-validation\n",
    "    verbose=2,\n",
    "    n_jobs=-1  # Use all available cores\n",
    ")\n",
    "\n",
    "# Fit GridSearchCV\n",
    "grid_search.fit(X_train_resampled_borderline, y_train_resampled_borderline)\n",
    "\n",
    "# Get the best model\n",
    "best_gnb_classifier = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on the test set using the best model\n",
    "y_pred_best_gnb = best_gnb_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the best model\n",
    "accuracy_best_gnb = accuracy_score(y_test, y_pred_best_gnb)\n",
    "classification_report_result_best_gnb = classification_report(y_test, y_pred_best_gnb, digits=3)\n",
    "\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "print(f\"Accuracy (Best GaussianNB with SMOTE): {accuracy_best_gnb}\")\n",
    "print(\"Classification Report (Best GaussianNB with SMOTE):\\n\", classification_report_result_best_gnb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Best Parameters: {'max_depth': None}\n",
      "Accuracy (Best Decision Tree with SMOTE): 0.9092565597667639\n",
      "Classification Report (Best Decision Tree with SMOTE):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0      0.847     0.813     0.830        75\n",
      "           1      0.746     0.883     0.809        60\n",
      "           2      0.918     0.863     0.890       182\n",
      "           3      0.970     0.865     0.914        37\n",
      "           4      0.927     0.962     0.944       212\n",
      "           5      0.707     0.844     0.769        77\n",
      "           6      0.949     0.907     0.928       248\n",
      "           7      0.902     0.902     0.902        41\n",
      "           8      0.852     0.897     0.874        58\n",
      "           9      0.946     0.940     0.943       167\n",
      "          10      0.976     0.930     0.952        43\n",
      "          11      0.548     0.607     0.576        28\n",
      "          12      0.915     0.985     0.949        66\n",
      "          13      0.981     0.937     0.959       223\n",
      "          14      0.867     0.812     0.839       112\n",
      "          15      0.924     0.938     0.931       194\n",
      "          16      0.918     0.944     0.931       178\n",
      "          17      0.656     0.808     0.724        26\n",
      "          18      0.863     0.863     0.863       102\n",
      "          19      0.865     0.918     0.891        49\n",
      "          20      0.987     0.954     0.970       410\n",
      "          21      0.860     0.865     0.863       156\n",
      "\n",
      "    accuracy                          0.909      2744\n",
      "   macro avg      0.869     0.884     0.875      2744\n",
      "weighted avg      0.913     0.909     0.910      2744\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'max_depth': [2, 3, 4, 5, None]\n",
    "}\n",
    "\n",
    "# Initialize the Decision Tree classifier\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=dt_classifier,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,  # 5-fold cross-validation\n",
    "    verbose=2,\n",
    "    n_jobs=-1  # Use all available cores\n",
    ")\n",
    "\n",
    "# Fit GridSearchCV\n",
    "grid_search.fit(X_train_resampled_smote, y_train_resampled_smote)\n",
    "\n",
    "# Get the best model\n",
    "best_dt_classifier = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on the test set using the best model\n",
    "y_pred_best_dt = best_dt_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the best model\n",
    "accuracy_best_dt = accuracy_score(y_test, y_pred_best_dt)\n",
    "classification_report_result_best_dt = classification_report(y_test, y_pred_best_dt, digits=3)\n",
    "\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "print(f\"Accuracy (Best Decision Tree with SMOTE): {accuracy_best_dt}\")\n",
    "print(\"Classification Report (Best Decision Tree with SMOTE):\\n\", classification_report_result_best_dt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Best Parameters: {'max_depth': None}\n",
      "Accuracy (Best Decision Tree with SMOTE): 0.9158163265306123\n",
      "Classification Report (Best Decision Tree with SMOTE):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0      0.775     0.827     0.800        75\n",
      "           1      0.724     0.917     0.809        60\n",
      "           2      0.901     0.901     0.901       182\n",
      "           3      0.872     0.919     0.895        37\n",
      "           4      0.947     0.929     0.938       212\n",
      "           5      0.829     0.883     0.855        77\n",
      "           6      0.944     0.891     0.917       248\n",
      "           7      0.950     0.927     0.938        41\n",
      "           8      0.823     0.879     0.850        58\n",
      "           9      0.890     0.916     0.903       167\n",
      "          10      1.000     1.000     1.000        43\n",
      "          11      0.615     0.571     0.593        28\n",
      "          12      0.970     0.970     0.970        66\n",
      "          13      0.991     0.955     0.973       223\n",
      "          14      0.879     0.839     0.858       112\n",
      "          15      0.943     0.943     0.943       194\n",
      "          16      0.919     0.955     0.937       178\n",
      "          17      0.808     0.808     0.808        26\n",
      "          18      0.862     0.922     0.891       102\n",
      "          19      0.830     0.898     0.863        49\n",
      "          20      0.990     0.949     0.969       410\n",
      "          21      0.914     0.891     0.903       156\n",
      "\n",
      "    accuracy                          0.916      2744\n",
      "   macro avg      0.881     0.895     0.887      2744\n",
      "weighted avg      0.918     0.916     0.916      2744\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'max_depth': [2, 3, 4, 5, None]\n",
    "}\n",
    "\n",
    "# Initialize the Decision Tree classifier\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=dt_classifier,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,  # 5-fold cross-validation\n",
    "    verbose=2,\n",
    "    n_jobs=-1  # Use all available cores\n",
    ")\n",
    "\n",
    "# Fit GridSearchCV\n",
    "grid_search.fit(X_train_resampled_borderline, y_train_resampled_borderline)\n",
    "\n",
    "# Get the best model\n",
    "best_dt_classifier = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on the test set using the best model\n",
    "y_pred_best_dt = best_dt_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the best model\n",
    "accuracy_best_dt = accuracy_score(y_test, y_pred_best_dt)\n",
    "classification_report_result_best_dt = classification_report(y_test, y_pred_best_dt, digits=3)\n",
    "\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "print(f\"Accuracy (Best Decision Tree with SMOTE): {accuracy_best_dt}\")\n",
    "print(\"Classification Report (Best Decision Tree with SMOTE):\\n\", classification_report_result_best_dt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Best Parameters: {'n_neighbors': 1}\n",
      "Accuracy (Best KNN with SMOTE): 0.6388483965014577\n",
      "Classification Report (Best KNN with SMOTE):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0      0.533     0.640     0.582        75\n",
      "           1      0.508     0.533     0.520        60\n",
      "           2      0.610     0.610     0.610       182\n",
      "           3      0.667     0.703     0.684        37\n",
      "           4      0.658     0.689     0.673       212\n",
      "           5      0.321     0.455     0.376        77\n",
      "           6      0.627     0.609     0.618       248\n",
      "           7      0.407     0.585     0.480        41\n",
      "           8      0.646     0.724     0.683        58\n",
      "           9      0.602     0.581     0.591       167\n",
      "          10      0.542     0.605     0.571        43\n",
      "          11      0.361     0.464     0.406        28\n",
      "          12      0.794     0.758     0.775        66\n",
      "          13      0.742     0.659     0.698       223\n",
      "          14      0.656     0.545     0.595       112\n",
      "          15      0.698     0.644     0.670       194\n",
      "          16      0.629     0.629     0.629       178\n",
      "          17      0.341     0.577     0.429        26\n",
      "          18      0.644     0.745     0.691       102\n",
      "          19      0.569     0.592     0.580        49\n",
      "          20      0.788     0.717     0.751       410\n",
      "          21      0.705     0.596     0.646       156\n",
      "\n",
      "    accuracy                          0.639      2744\n",
      "   macro avg      0.593     0.621     0.603      2744\n",
      "weighted avg      0.652     0.639     0.643      2744\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assume X_final and y_encoded are your features and target after preprocessing\n",
    "\n",
    "\n",
    "# Apply StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Apply SMOTE to the training data only\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "# Define the parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'n_neighbors': [1, 2, 3, 4, 5]\n",
    "}\n",
    "\n",
    "# Initialize the KNN classifier\n",
    "knn_classifier = KNeighborsClassifier()\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=knn_classifier,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,  # 5-fold cross-validation\n",
    "    verbose=2,\n",
    "    n_jobs=-1  # Use all available cores\n",
    ")\n",
    "\n",
    "# Fit GridSearchCV with resampled data\n",
    "grid_search.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Get the best model\n",
    "best_knn_classifier = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on the test set using the best model\n",
    "y_pred_best_knn = best_knn_classifier.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the best model\n",
    "accuracy_best_knn = accuracy_score(y_test, y_pred_best_knn)\n",
    "classification_report_result_best_knn = classification_report(y_test, y_pred_best_knn, digits=3)\n",
    "\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "print(f\"Accuracy (Best KNN with SMOTE): {accuracy_best_knn}\")\n",
    "print(\"Classification Report (Best KNN with SMOTE):\\n\", classification_report_result_best_knn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Best Parameters: {'n_neighbors': 1}\n",
      "Accuracy (Best KNN with Borderline SMOTE): 0.6428571428571429\n",
      "Classification Report (Best KNN with Borderline SMOTE):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0      0.548     0.613     0.579        75\n",
      "           1      0.508     0.550     0.528        60\n",
      "           2      0.629     0.604     0.616       182\n",
      "           3      0.675     0.730     0.701        37\n",
      "           4      0.654     0.712     0.682       212\n",
      "           5      0.343     0.455     0.391        77\n",
      "           6      0.619     0.629     0.624       248\n",
      "           7      0.444     0.585     0.505        41\n",
      "           8      0.683     0.707     0.695        58\n",
      "           9      0.608     0.605     0.607       167\n",
      "          10      0.529     0.628     0.574        43\n",
      "          11      0.387     0.429     0.407        28\n",
      "          12      0.781     0.758     0.769        66\n",
      "          13      0.723     0.655     0.687       223\n",
      "          14      0.656     0.545     0.595       112\n",
      "          15      0.686     0.655     0.670       194\n",
      "          16      0.616     0.596     0.606       178\n",
      "          17      0.371     0.500     0.426        26\n",
      "          18      0.641     0.735     0.685       102\n",
      "          19      0.622     0.571     0.596        49\n",
      "          20      0.789     0.722     0.754       410\n",
      "          21      0.683     0.635     0.658       156\n",
      "\n",
      "    accuracy                          0.643      2744\n",
      "   macro avg      0.600     0.619     0.607      2744\n",
      "weighted avg      0.651     0.643     0.646      2744\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assume X_final and y_encoded are your features and target after preprocessing\n",
    "\n",
    "\n",
    "# Apply StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Apply Borderline SMOTE to the training data only\n",
    "smote = BorderlineSMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "# Define the parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'n_neighbors': [1, 2, 3, 4, 5]\n",
    "}\n",
    "\n",
    "# Initialize the KNN classifier\n",
    "knn_classifier = KNeighborsClassifier()\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=knn_classifier,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,  # 5-fold cross-validation\n",
    "    verbose=2,\n",
    "    n_jobs=-1  # Use all available cores\n",
    ")\n",
    "\n",
    "# Fit GridSearchCV with resampled data\n",
    "grid_search.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Get the best model\n",
    "best_knn_classifier = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on the test set using the best model\n",
    "y_pred_best_knn = best_knn_classifier.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the best model\n",
    "accuracy_best_knn = accuracy_score(y_test, y_pred_best_knn)\n",
    "classification_report_result_best_knn = classification_report(y_test, y_pred_best_knn, digits=3)\n",
    "\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "print(f\"Accuracy (Best KNN with Borderline SMOTE): {accuracy_best_knn}\")\n",
    "print(\"Classification Report (Best KNN with Borderline SMOTE):\\n\", classification_report_result_best_knn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "Best Parameters (SVM with SMOTE): {'C': 100, 'gamma': 0.1}\n",
      "Accuracy (SVM with SMOTE): 0.7959183673469388\n",
      "Classification Report (SVM with SMOTE):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0      0.604     0.773     0.678        75\n",
      "           1      0.742     0.817     0.778        60\n",
      "           2      0.778     0.808     0.792       182\n",
      "           3      0.842     0.865     0.853        37\n",
      "           4      0.770     0.887     0.825       212\n",
      "           5      0.513     0.519     0.516        77\n",
      "           6      0.715     0.730     0.723       248\n",
      "           7      0.844     0.927     0.884        41\n",
      "           8      0.741     0.741     0.741        58\n",
      "           9      0.821     0.713     0.763       167\n",
      "          10      0.821     0.744     0.780        43\n",
      "          11      0.522     0.429     0.471        28\n",
      "          12      0.905     0.864     0.884        66\n",
      "          13      0.891     0.883     0.887       223\n",
      "          14      0.882     0.732     0.800       112\n",
      "          15      0.832     0.814     0.823       194\n",
      "          16      0.715     0.719     0.717       178\n",
      "          17      0.615     0.615     0.615        26\n",
      "          18      0.809     0.873     0.840       102\n",
      "          19      0.761     0.714     0.737        49\n",
      "          20      0.885     0.878     0.881       410\n",
      "          21      0.911     0.788     0.845       156\n",
      "\n",
      "    accuracy                          0.796      2744\n",
      "   macro avg      0.769     0.765     0.765      2744\n",
      "weighted avg      0.800     0.796     0.796      2744\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "\n",
    "\n",
    "# Apply StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Apply SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "# Define the parameter grid for SVM\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'gamma': [1, 0.1, 0.01, 0.001],\n",
    "}\n",
    "\n",
    "# Initialize the SVM classifier\n",
    "svm_classifier = SVC()\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=svm_classifier,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,  # 5-fold cross-validation\n",
    "    verbose=2,\n",
    "    n_jobs=-1  # Use all available cores\n",
    ")\n",
    "\n",
    "# Fit GridSearchCV\n",
    "grid_search.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Get the best model\n",
    "best_svm_classifier = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on the test set using the best model\n",
    "y_pred_best_svm = best_svm_classifier.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the best model\n",
    "accuracy_best_svm = accuracy_score(y_test, y_pred_best_svm)\n",
    "classification_report_result_best_svm = classification_report(y_test, y_pred_best_svm, digits=3)\n",
    "\n",
    "# Print results\n",
    "print(f\"Best Parameters (SVM with SMOTE): {grid_search.best_params_}\")\n",
    "print(f\"Accuracy (SVM with SMOTE): {accuracy_best_svm}\")\n",
    "print(\"Classification Report (SVM with SMOTE):\\n\", classification_report_result_best_svm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "Best Parameters (SVM with BorderlineSMOTE): {'C': 100, 'gamma': 0.1}\n",
      "Accuracy (SVM with BorderlineSMOTE): 0.8032069970845481\n",
      "Classification Report (SVM with BorderlineSMOTE):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0      0.648     0.760     0.699        75\n",
      "           1      0.729     0.850     0.785        60\n",
      "           2      0.772     0.819     0.795       182\n",
      "           3      0.842     0.865     0.853        37\n",
      "           4      0.757     0.882     0.815       212\n",
      "           5      0.554     0.532     0.543        77\n",
      "           6      0.750     0.762     0.756       248\n",
      "           7      0.860     0.902     0.881        41\n",
      "           8      0.811     0.741     0.775        58\n",
      "           9      0.827     0.772     0.799       167\n",
      "          10      0.795     0.721     0.756        43\n",
      "          11      0.520     0.464     0.491        28\n",
      "          12      0.923     0.909     0.916        66\n",
      "          13      0.873     0.865     0.869       223\n",
      "          14      0.863     0.732     0.792       112\n",
      "          15      0.817     0.804     0.810       194\n",
      "          16      0.739     0.730     0.734       178\n",
      "          17      0.708     0.654     0.680        26\n",
      "          18      0.796     0.843     0.819       102\n",
      "          19      0.810     0.694     0.747        49\n",
      "          20      0.894     0.883     0.888       410\n",
      "          21      0.899     0.801     0.847       156\n",
      "\n",
      "    accuracy                          0.803      2744\n",
      "   macro avg      0.781     0.772     0.775      2744\n",
      "weighted avg      0.806     0.803     0.803      2744\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "\n",
    "# Assuming X_train, X_test, y_train, y_test are already defined\n",
    "# Apply StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Apply BorderlineSMOTE\n",
    "borderline_smote = BorderlineSMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = borderline_smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "# Define the parameter grid for SVM\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'gamma': [1, 0.1, 0.01, 0.001],\n",
    "}\n",
    "\n",
    "# Initialize the SVM classifier\n",
    "svm_classifier = SVC()\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=svm_classifier,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,  # 5-fold cross-validation\n",
    "    verbose=2,\n",
    "    n_jobs=-1  # Use all available cores\n",
    ")\n",
    "\n",
    "# Fit GridSearchCV\n",
    "grid_search.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Get the best model\n",
    "best_svm_classifier = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on the test set using the best model\n",
    "y_pred_best_svm = best_svm_classifier.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the best model\n",
    "accuracy_best_svm = accuracy_score(y_test, y_pred_best_svm)\n",
    "classification_report_result_best_svm = classification_report(y_test, y_pred_best_svm, digits=3)\n",
    "\n",
    "# Print results\n",
    "print(f\"Best Parameters (SVM with BorderlineSMOTE): {grid_search.best_params_}\")\n",
    "print(f\"Accuracy (SVM with BorderlineSMOTE): {accuracy_best_svm}\")\n",
    "print(\"Classification Report (SVM with BorderlineSMOTE):\\n\", classification_report_result_best_svm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "Best Parameters (Logistic Regression with SMOTE): {'C': 10, 'solver': 'lbfgs'}\n",
      "Accuracy (Logistic Regression with SMOTE): 0.2631195335276968\n",
      "Classification Report (Logistic Regression with SMOTE):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0      0.056     0.013     0.022        75\n",
      "           1      0.069     0.067     0.068        60\n",
      "           2      0.507     0.203     0.290       182\n",
      "           3      0.290     0.784     0.423        37\n",
      "           4      0.483     0.264     0.341       212\n",
      "           5      0.125     0.429     0.194        77\n",
      "           6      0.412     0.218     0.285       248\n",
      "           7      0.158     0.927     0.270        41\n",
      "           8      0.299     0.655     0.411        58\n",
      "           9      0.175     0.192     0.183       167\n",
      "          10      0.192     0.744     0.305        43\n",
      "          11      0.133     0.464     0.206        28\n",
      "          12      0.345     0.758     0.474        66\n",
      "          13      0.449     0.435     0.442       223\n",
      "          14      0.352     0.330     0.341       112\n",
      "          15      0.292     0.144     0.193       194\n",
      "          16      0.250     0.140     0.180       178\n",
      "          17      0.132     0.346     0.191        26\n",
      "          18      0.308     0.480     0.375       102\n",
      "          19      0.095     0.327     0.147        49\n",
      "          20      0.379     0.080     0.133       410\n",
      "          21      0.478     0.071     0.123       156\n",
      "\n",
      "    accuracy                          0.263      2744\n",
      "   macro avg      0.272     0.367     0.254      2744\n",
      "weighted avg      0.337     0.263     0.247      2744\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Assuming X_train, X_test, y_train, y_test are already defined\n",
    "# Apply StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Apply SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "# Define the parameter grid for Logistic Regression\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'solver': ['lbfgs', 'liblinear'],  # Choose either 'lbfgs' or 'liblinear' solver\n",
    "}\n",
    "\n",
    "# Initialize the Logistic Regression classifier\n",
    "lr_classifier = LogisticRegression(max_iter=1000)  # Increase max_iter if necessary\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=lr_classifier,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,  # 5-fold cross-validation\n",
    "    verbose=2,\n",
    "    n_jobs=-1  # Use all available cores\n",
    ")\n",
    "\n",
    "# Fit GridSearchCV\n",
    "grid_search.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Get the best model\n",
    "best_lr_classifier = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on the test set using the best model\n",
    "y_pred_best_lr = best_lr_classifier.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the best model\n",
    "accuracy_best_lr = accuracy_score(y_test, y_pred_best_lr)\n",
    "classification_report_result_best_lr = classification_report(y_test, y_pred_best_lr, digits=3)\n",
    "\n",
    "# Print results\n",
    "print(f\"Best Parameters (Logistic Regression with SMOTE): {grid_search.best_params_}\")\n",
    "print(f\"Accuracy (Logistic Regression with SMOTE): {accuracy_best_lr}\")\n",
    "print(\"Classification Report (Logistic Regression with SMOTE):\\n\", classification_report_result_best_lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "Best Parameters (Logistic Regression with BorderlineSMOTE): {'C': 10, 'solver': 'lbfgs'}\n",
      "Accuracy (Logistic Regression with BorderlineSMOTE): 0.2478134110787172\n",
      "Classification Report (Logistic Regression with BorderlineSMOTE):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0      0.167     0.067     0.095        75\n",
      "           1      0.065     0.067     0.066        60\n",
      "           2      0.407     0.181     0.251       182\n",
      "           3      0.267     0.730     0.391        37\n",
      "           4      0.434     0.250     0.317       212\n",
      "           5      0.168     0.558     0.258        77\n",
      "           6      0.337     0.133     0.191       248\n",
      "           7      0.170     0.927     0.288        41\n",
      "           8      0.322     0.655     0.432        58\n",
      "           9      0.157     0.186     0.170       167\n",
      "          10      0.183     0.744     0.294        43\n",
      "          11      0.136     0.429     0.207        28\n",
      "          12      0.307     0.712     0.429        66\n",
      "          13      0.429     0.462     0.445       223\n",
      "          14      0.325     0.330     0.327       112\n",
      "          15      0.267     0.124     0.169       194\n",
      "          16      0.191     0.096     0.127       178\n",
      "          17      0.113     0.346     0.170        26\n",
      "          18      0.287     0.422     0.341       102\n",
      "          19      0.047     0.163     0.072        49\n",
      "          20      0.452     0.093     0.154       410\n",
      "          21      0.238     0.032     0.056       156\n",
      "\n",
      "    accuracy                          0.248      2744\n",
      "   macro avg      0.249     0.350     0.239      2744\n",
      "weighted avg      0.309     0.248     0.227      2744\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "\n",
    "# Assuming X_train, X_test, y_train, y_test are already defined\n",
    "# Apply StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Apply BorderlineSMOTE\n",
    "smote = BorderlineSMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "# Define the parameter grid for Logistic Regression\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'solver': ['lbfgs', 'liblinear'],  # Choose either 'lbfgs' or 'liblinear' solver\n",
    "}\n",
    "\n",
    "# Initialize the Logistic Regression classifier\n",
    "lr_classifier = LogisticRegression(max_iter=1000)  # Increase max_iter if necessary\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=lr_classifier,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,  # 5-fold cross-validation\n",
    "    verbose=2,\n",
    "    n_jobs=-1  # Use all available cores\n",
    ")\n",
    "\n",
    "# Fit GridSearchCV\n",
    "grid_search.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Get the best model\n",
    "best_lr_classifier = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on the test set using the best model\n",
    "y_pred_best_lr = best_lr_classifier.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the best model\n",
    "accuracy_best_lr = accuracy_score(y_test, y_pred_best_lr)\n",
    "classification_report_result_best_lr = classification_report(y_test, y_pred_best_lr, digits=3)\n",
    "\n",
    "# Print results\n",
    "print(f\"Best Parameters (Logistic Regression with BorderlineSMOTE): {grid_search.best_params_}\")\n",
    "print(f\"Accuracy (Logistic Regression with BorderlineSMOTE): {accuracy_best_lr}\")\n",
    "print(\"Classification Report (Logistic Regression with BorderlineSMOTE):\\n\", classification_report_result_best_lr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "Best Parameters (XGBoost with SMOTE): {'gamma': None, 'max_depth': None}\n",
      "Accuracy (XGBoost with SMOTE): 0.9577259475218659\n",
      "Classification Report (XGBoost with SMOTE):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0      0.932     0.920     0.926        75\n",
      "           1      0.932     0.917     0.924        60\n",
      "           2      0.961     0.940     0.950       182\n",
      "           3      1.000     0.946     0.972        37\n",
      "           4      0.935     0.958     0.946       212\n",
      "           5      0.892     0.961     0.925        77\n",
      "           6      0.980     0.968     0.974       248\n",
      "           7      0.976     1.000     0.988        41\n",
      "           8      0.914     0.914     0.914        58\n",
      "           9      0.930     0.958     0.944       167\n",
      "          10      1.000     1.000     1.000        43\n",
      "          11      0.750     0.750     0.750        28\n",
      "          12      1.000     1.000     1.000        66\n",
      "          13      0.991     0.982     0.986       223\n",
      "          14      0.915     0.866     0.890       112\n",
      "          15      0.968     0.948     0.958       194\n",
      "          16      0.934     0.955     0.944       178\n",
      "          17      0.917     0.846     0.880        26\n",
      "          18      0.935     0.980     0.957       102\n",
      "          19      1.000     0.939     0.968        49\n",
      "          20      0.993     0.993     0.993       410\n",
      "          21      0.962     0.974     0.968       156\n",
      "\n",
      "    accuracy                          0.958      2744\n",
      "   macro avg      0.946     0.942     0.944      2744\n",
      "weighted avg      0.958     0.958     0.958      2744\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')  # Ignore warnings for simplicity\n",
    "\n",
    "# Define the parameter grid for XGBoost\n",
    "param_grid = {\n",
    "    'max_depth': [2, 3, 4, 5, None],\n",
    "    'gamma': [0.1, 0.2, 0.3, 0.4, 0.5, None],\n",
    "}\n",
    "\n",
    "# Initialize the XGBoost classifier\n",
    "xgb_classifier = XGBClassifier(random_state=42)\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=xgb_classifier,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,  # 5-fold cross-validation\n",
    "    verbose=2,\n",
    "    n_jobs=-1  # Use all available cores\n",
    ")\n",
    "\n",
    "# Fit GridSearchCV\n",
    "grid_search.fit(X_train_resampled_smote, y_train_resampled_smote)\n",
    "\n",
    "# Get the best model\n",
    "best_xgb_classifier = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on the test set using the best model\n",
    "y_pred_best_xgb = best_xgb_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the best model\n",
    "accuracy_best_xgb = accuracy_score(y_test, y_pred_best_xgb)\n",
    "classification_report_result_best_xgb = classification_report(y_test, y_pred_best_xgb, digits=3)\n",
    "\n",
    "# Print results\n",
    "print(f\"Best Parameters (XGBoost with SMOTE): {grid_search.best_params_}\")\n",
    "print(f\"Accuracy (XGBoost with SMOTE): {accuracy_best_xgb}\")\n",
    "print(\"Classification Report (XGBoost with SMOTE):\\n\", classification_report_result_best_xgb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "Best Parameters (XGBoost with SMOTE): {'gamma': None, 'max_depth': None}\n",
      "Accuracy (XGBoost with SMOTE): 0.9661078717201166\n",
      "Classification Report (XGBoost with SMOTE):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0      0.909     0.933     0.921        75\n",
      "           1      0.966     0.950     0.958        60\n",
      "           2      0.956     0.956     0.956       182\n",
      "           3      1.000     1.000     1.000        37\n",
      "           4      0.944     0.958     0.951       212\n",
      "           5      0.949     0.974     0.962        77\n",
      "           6      0.980     0.980     0.980       248\n",
      "           7      1.000     1.000     1.000        41\n",
      "           8      0.931     0.931     0.931        58\n",
      "           9      0.970     0.964     0.967       167\n",
      "          10      1.000     1.000     1.000        43\n",
      "          11      0.955     0.750     0.840        28\n",
      "          12      1.000     1.000     1.000        66\n",
      "          13      0.995     0.982     0.989       223\n",
      "          14      0.909     0.893     0.901       112\n",
      "          15      0.974     0.979     0.977       194\n",
      "          16      0.956     0.978     0.967       178\n",
      "          17      0.880     0.846     0.863        26\n",
      "          18      0.943     0.980     0.962       102\n",
      "          19      1.000     0.878     0.935        49\n",
      "          20      0.988     0.988     0.988       410\n",
      "          21      0.956     0.981     0.968       156\n",
      "\n",
      "    accuracy                          0.966      2744\n",
      "   macro avg      0.962     0.950     0.955      2744\n",
      "weighted avg      0.966     0.966     0.966      2744\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')  # Ignore warnings for simplicity\n",
    "\n",
    "# Define the parameter grid for XGBoost\n",
    "param_grid = {\n",
    "    'max_depth': [2, 3, 4, 5, None],\n",
    "    'gamma': [0.1, 0.2, 0.3, 0.4, 0.5, None],\n",
    "}\n",
    "\n",
    "# Initialize the XGBoost classifier\n",
    "xgb_classifier = XGBClassifier(random_state=42)\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=xgb_classifier,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,  # 5-fold cross-validation\n",
    "    verbose=2,\n",
    "    n_jobs=-1  # Use all available cores\n",
    ")\n",
    "\n",
    "# Fit GridSearchCV\n",
    "grid_search.fit(X_train_resampled_borderline, y_train_resampled_borderline)\n",
    "\n",
    "# Get the best model\n",
    "best_xgb_classifier = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on the test set using the best model\n",
    "y_pred_best_xgb = best_xgb_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the best model\n",
    "accuracy_best_xgb = accuracy_score(y_test, y_pred_best_xgb)\n",
    "classification_report_result_best_xgb = classification_report(y_test, y_pred_best_xgb, digits=3)\n",
    "\n",
    "# Print results\n",
    "print(f\"Best Parameters (XGBoost with SMOTE): {grid_search.best_params_}\")\n",
    "print(f\"Accuracy (XGBoost with SMOTE): {accuracy_best_xgb}\")\n",
    "print(\"Classification Report (XGBoost with SMOTE):\\n\", classification_report_result_best_xgb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline XGBoost Model:\n",
      "Accuracy: 0.989067055393586\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0      0.987     0.987     0.987        75\n",
      "           1      0.984     1.000     0.992        60\n",
      "           2      0.984     0.989     0.986       182\n",
      "           3      1.000     0.973     0.986        37\n",
      "           4      0.981     0.981     0.981       212\n",
      "           5      0.975     1.000     0.987        77\n",
      "           6      0.984     1.000     0.992       248\n",
      "           7      1.000     1.000     1.000        41\n",
      "           8      0.983     0.983     0.983        58\n",
      "           9      1.000     0.982     0.991       167\n",
      "          10      1.000     1.000     1.000        43\n",
      "          11      1.000     0.786     0.880        28\n",
      "          12      1.000     1.000     1.000        66\n",
      "          13      1.000     0.996     0.998       223\n",
      "          14      0.964     0.955     0.960       112\n",
      "          15      1.000     0.995     0.997       194\n",
      "          16      0.989     0.994     0.992       178\n",
      "          17      1.000     0.923     0.960        26\n",
      "          18      0.990     1.000     0.995       102\n",
      "          19      1.000     0.959     0.979        49\n",
      "          20      0.986     1.000     0.993       410\n",
      "          21      0.994     1.000     0.997       156\n",
      "\n",
      "    accuracy                          0.989      2744\n",
      "   macro avg      0.991     0.977     0.983      2744\n",
      "weighted avg      0.989     0.989     0.989      2744\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Initialize the XGBoost classifier with default parameters\n",
    "xgb_classifier_baseline = XGBClassifier(random_state=42)\n",
    "\n",
    "# Fit the classifier on the training data (assuming X_train and y_train are defined)\n",
    "xgb_classifier_baseline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_xgb_baseline = xgb_classifier_baseline.predict(X_test)\n",
    "\n",
    "# Evaluate the baseline model\n",
    "accuracy_xgb_baseline = accuracy_score(y_test, y_pred_xgb_baseline)\n",
    "classification_report_result_xgb_baseline = classification_report(y_test, y_pred_xgb_baseline, digits=3)\n",
    "\n",
    "# Print results\n",
    "print(\"Baseline XGBoost Model:\")\n",
    "print(f\"Accuracy: {accuracy_xgb_baseline}\")\n",
    "print(\"Classification Report:\\n\", classification_report_result_xgb_baseline)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Best Parameters (AdaBoost with SMOTE): {'learning_rate': 0.1, 'n_estimators': 100}\n",
      "Accuracy (AdaBoost with SMOTE): 0.28316326530612246\n",
      "Classification Report (AdaBoost with SMOTE):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0      0.383     0.240     0.295        75\n",
      "           1      0.000     0.000     0.000        60\n",
      "           2      0.471     0.484     0.477       182\n",
      "           3      0.604     0.784     0.682        37\n",
      "           4      0.685     0.288     0.405       212\n",
      "           5      0.067     0.130     0.088        77\n",
      "           6      0.197     0.060     0.093       248\n",
      "           7      0.528     0.683     0.596        41\n",
      "           8      0.500     0.052     0.094        58\n",
      "           9      0.125     0.084     0.100       167\n",
      "          10      0.727     0.372     0.492        43\n",
      "          11      0.120     0.714     0.206        28\n",
      "          12      0.319     0.682     0.435        66\n",
      "          13      1.000     0.027     0.052       223\n",
      "          14      0.188     0.393     0.254       112\n",
      "          15      0.391     0.258     0.311       194\n",
      "          16      0.264     0.320     0.289       178\n",
      "          17      0.028     0.500     0.053        26\n",
      "          18      0.533     0.637     0.580       102\n",
      "          19      0.140     0.286     0.188        49\n",
      "          20      0.494     0.322     0.390       410\n",
      "          21      0.462     0.314     0.374       156\n",
      "\n",
      "    accuracy                          0.283      2744\n",
      "   macro avg      0.374     0.347     0.293      2744\n",
      "weighted avg      0.425     0.283     0.289      2744\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')  # Ignore warnings for simplicity\n",
    "\n",
    "\n",
    "# Define the parameter grid for AdaBoost\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150, 200],\n",
    "    'learning_rate': [0.001, 0.1, 1],\n",
    "}\n",
    "\n",
    "# Initialize the AdaBoost classifier\n",
    "ada_classifier = AdaBoostClassifier(random_state=42)\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=ada_classifier,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,  # 5-fold cross-validation\n",
    "    verbose=2,\n",
    "    n_jobs=-1  # Use all available cores\n",
    ")\n",
    "\n",
    "# Fit GridSearchCV on resampled data\n",
    "grid_search.fit(X_train_resampled_smote, y_train_resampled_smote)\n",
    "\n",
    "# Get the best model\n",
    "best_ada_classifier = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on the test set using the best model\n",
    "y_pred_best_ada = best_ada_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the best model\n",
    "accuracy_best_ada = accuracy_score(y_test, y_pred_best_ada)\n",
    "classification_report_result_best_ada = classification_report(y_test, y_pred_best_ada, digits=3)\n",
    "\n",
    "# Print results\n",
    "print(f\"Best Parameters (AdaBoost with SMOTE): {grid_search.best_params_}\")\n",
    "print(f\"Accuracy (AdaBoost with SMOTE): {accuracy_best_ada}\")\n",
    "print(\"Classification Report (AdaBoost with SMOTE):\\n\", classification_report_result_best_ada)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Best Parameters (AdaBoost with SMOTE): {'learning_rate': 0.1, 'n_estimators': 100}\n",
      "Accuracy (AdaBoost with SMOTE): 0.3086734693877551\n",
      "Classification Report (AdaBoost with SMOTE):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0      0.409     0.240     0.303        75\n",
      "           1      0.000     0.000     0.000        60\n",
      "           2      0.567     0.533     0.550       182\n",
      "           3      0.724     0.568     0.636        37\n",
      "           4      0.681     0.231     0.345       212\n",
      "           5      0.078     0.234     0.117        77\n",
      "           6      0.382     0.137     0.202       248\n",
      "           7      0.788     0.634     0.703        41\n",
      "           8      1.000     0.155     0.269        58\n",
      "           9      0.183     0.126     0.149       167\n",
      "          10      0.810     0.395     0.531        43\n",
      "          11      0.175     0.714     0.282        28\n",
      "          12      0.321     0.409     0.360        66\n",
      "          13      0.500     0.013     0.026       223\n",
      "          14      0.227     0.562     0.324       112\n",
      "          15      0.070     0.026     0.038       194\n",
      "          16      0.254     0.461     0.327       178\n",
      "          17      0.052     0.500     0.094        26\n",
      "          18      0.497     0.706     0.583       102\n",
      "          19      0.141     0.265     0.184        49\n",
      "          20      0.424     0.454     0.438       410\n",
      "          21      0.438     0.340     0.383       156\n",
      "\n",
      "    accuracy                          0.309      2744\n",
      "   macro avg      0.396     0.350     0.311      2744\n",
      "weighted avg      0.395     0.309     0.299      2744\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')  # Ignore warnings for simplicity\n",
    "\n",
    "\n",
    "# Define the parameter grid for AdaBoost\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150, 200],\n",
    "    'learning_rate': [0.001, 0.1, 1],\n",
    "}\n",
    "\n",
    "# Initialize the AdaBoost classifier\n",
    "ada_classifier = AdaBoostClassifier(random_state=42)\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=ada_classifier,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,  # 5-fold cross-validation\n",
    "    verbose=2,\n",
    "    n_jobs=-1  # Use all available cores\n",
    ")\n",
    "\n",
    "# Fit GridSearchCV on resampled data\n",
    "grid_search.fit(X_train_resampled_borderline, y_train_resampled_borderline)\n",
    "\n",
    "# Get the best model\n",
    "best_ada_classifier = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on the test set using the best model\n",
    "y_pred_best_ada = best_ada_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the best model\n",
    "accuracy_best_ada = accuracy_score(y_test, y_pred_best_ada)\n",
    "classification_report_result_best_ada = classification_report(y_test, y_pred_best_ada, digits=3)\n",
    "\n",
    "# Print results\n",
    "print(f\"Best Parameters (AdaBoost with SMOTE): {grid_search.best_params_}\")\n",
    "print(f\"Accuracy (AdaBoost with SMOTE): {accuracy_best_ada}\")\n",
    "print(\"Classification Report (AdaBoost with SMOTE):\\n\", classification_report_result_best_ada)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline AdaBoost Model:\n",
      "Accuracy: 0.19533527696793002\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0      0.000     0.000     0.000        75\n",
      "           1      0.000     0.000     0.000        60\n",
      "           2      0.122     0.478     0.194       182\n",
      "           3      0.000     0.000     0.000        37\n",
      "           4      0.198     0.844     0.321       212\n",
      "           5      0.000     0.000     0.000        77\n",
      "           6      0.000     0.000     0.000       248\n",
      "           7      0.000     0.000     0.000        41\n",
      "           8      0.000     0.000     0.000        58\n",
      "           9      0.000     0.000     0.000       167\n",
      "          10      0.000     0.000     0.000        43\n",
      "          11      0.000     0.000     0.000        28\n",
      "          12      0.000     0.000     0.000        66\n",
      "          13      0.000     0.000     0.000       223\n",
      "          14      0.000     0.000     0.000       112\n",
      "          15      0.473     0.361     0.409       194\n",
      "          16      0.714     0.028     0.054       178\n",
      "          17      0.000     0.000     0.000        26\n",
      "          18      0.000     0.000     0.000       102\n",
      "          19      0.000     0.000     0.000        49\n",
      "          20      0.200     0.476     0.282       410\n",
      "          21      0.000     0.000     0.000       156\n",
      "\n",
      "    accuracy                          0.195      2744\n",
      "   macro avg      0.078     0.099     0.057      2744\n",
      "weighted avg      0.133     0.195     0.112      2744\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Initialize the AdaBoost classifier with default parameters\n",
    "ada_classifier_baseline = AdaBoostClassifier(random_state=42)\n",
    "\n",
    "# Fit the classifier on the training data (assuming X_train and y_train are defined)\n",
    "ada_classifier_baseline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_ada_baseline = ada_classifier_baseline.predict(X_test)\n",
    "\n",
    "# Evaluate the baseline model\n",
    "accuracy_ada_baseline = accuracy_score(y_test, y_pred_ada_baseline)\n",
    "classification_report_result_ada_baseline = classification_report(y_test, y_pred_ada_baseline, digits=3)\n",
    "\n",
    "# Print results\n",
    "print(\"Baseline AdaBoost Model:\")\n",
    "print(f\"Accuracy: {accuracy_ada_baseline}\")\n",
    "print(\"Classification Report:\\n\", classification_report_result_ada_baseline)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.08941\n",
      "0:\tlearn: 2.8229482\ttotal: 397ms\tremaining: 6m 36s\n",
      "1:\tlearn: 2.6119468\ttotal: 505ms\tremaining: 4m 12s\n",
      "2:\tlearn: 2.4468491\ttotal: 563ms\tremaining: 3m 7s\n",
      "3:\tlearn: 2.3238602\ttotal: 629ms\tremaining: 2m 36s\n",
      "4:\tlearn: 2.2090412\ttotal: 704ms\tremaining: 2m 20s\n",
      "5:\tlearn: 2.1230324\ttotal: 766ms\tremaining: 2m 6s\n",
      "6:\tlearn: 2.0393641\ttotal: 822ms\tremaining: 1m 56s\n",
      "7:\tlearn: 1.9688408\ttotal: 882ms\tremaining: 1m 49s\n",
      "8:\tlearn: 1.9052184\ttotal: 952ms\tremaining: 1m 44s\n",
      "9:\tlearn: 1.8473436\ttotal: 1.01s\tremaining: 1m 40s\n",
      "10:\tlearn: 1.7773804\ttotal: 1.06s\tremaining: 1m 35s\n",
      "11:\tlearn: 1.7188466\ttotal: 1.13s\tremaining: 1m 33s\n",
      "12:\tlearn: 1.6663020\ttotal: 1.19s\tremaining: 1m 30s\n",
      "13:\tlearn: 1.6273779\ttotal: 1.25s\tremaining: 1m 27s\n",
      "14:\tlearn: 1.5886580\ttotal: 1.31s\tremaining: 1m 26s\n",
      "15:\tlearn: 1.5468560\ttotal: 1.38s\tremaining: 1m 24s\n",
      "16:\tlearn: 1.5161634\ttotal: 1.46s\tremaining: 1m 24s\n",
      "17:\tlearn: 1.4646648\ttotal: 1.51s\tremaining: 1m 22s\n",
      "18:\tlearn: 1.4314792\ttotal: 1.57s\tremaining: 1m 21s\n",
      "19:\tlearn: 1.4082497\ttotal: 1.63s\tremaining: 1m 19s\n",
      "20:\tlearn: 1.3807166\ttotal: 1.68s\tremaining: 1m 18s\n",
      "21:\tlearn: 1.3488777\ttotal: 1.75s\tremaining: 1m 17s\n",
      "22:\tlearn: 1.3149303\ttotal: 1.81s\tremaining: 1m 16s\n",
      "23:\tlearn: 1.3011412\ttotal: 1.86s\tremaining: 1m 15s\n",
      "24:\tlearn: 1.2773623\ttotal: 1.93s\tremaining: 1m 15s\n",
      "25:\tlearn: 1.2438126\ttotal: 1.98s\tremaining: 1m 14s\n",
      "26:\tlearn: 1.2193190\ttotal: 2.04s\tremaining: 1m 13s\n",
      "27:\tlearn: 1.1980018\ttotal: 2.1s\tremaining: 1m 12s\n",
      "28:\tlearn: 1.1698515\ttotal: 2.16s\tremaining: 1m 12s\n",
      "29:\tlearn: 1.1548974\ttotal: 2.22s\tremaining: 1m 11s\n",
      "30:\tlearn: 1.1317098\ttotal: 2.29s\tremaining: 1m 11s\n",
      "31:\tlearn: 1.1151756\ttotal: 2.36s\tremaining: 1m 11s\n",
      "32:\tlearn: 1.1013473\ttotal: 2.42s\tremaining: 1m 11s\n",
      "33:\tlearn: 1.0895778\ttotal: 2.49s\tremaining: 1m 10s\n",
      "34:\tlearn: 1.0816922\ttotal: 2.55s\tremaining: 1m 10s\n",
      "35:\tlearn: 1.0557742\ttotal: 2.62s\tremaining: 1m 10s\n",
      "36:\tlearn: 1.0361081\ttotal: 2.7s\tremaining: 1m 10s\n",
      "37:\tlearn: 1.0203350\ttotal: 2.78s\tremaining: 1m 10s\n",
      "38:\tlearn: 1.0097084\ttotal: 2.84s\tremaining: 1m 9s\n",
      "39:\tlearn: 0.9956650\ttotal: 2.89s\tremaining: 1m 9s\n",
      "40:\tlearn: 0.9824573\ttotal: 2.96s\tremaining: 1m 9s\n",
      "41:\tlearn: 0.9599250\ttotal: 3.01s\tremaining: 1m 8s\n",
      "42:\tlearn: 0.9499488\ttotal: 3.08s\tremaining: 1m 8s\n",
      "43:\tlearn: 0.9383838\ttotal: 3.14s\tremaining: 1m 8s\n",
      "44:\tlearn: 0.9287752\ttotal: 3.2s\tremaining: 1m 7s\n",
      "45:\tlearn: 0.9153453\ttotal: 3.27s\tremaining: 1m 7s\n",
      "46:\tlearn: 0.9048284\ttotal: 3.33s\tremaining: 1m 7s\n",
      "47:\tlearn: 0.8918198\ttotal: 3.41s\tremaining: 1m 7s\n",
      "48:\tlearn: 0.8837850\ttotal: 3.46s\tremaining: 1m 7s\n",
      "49:\tlearn: 0.8723978\ttotal: 3.53s\tremaining: 1m 7s\n",
      "50:\tlearn: 0.8581603\ttotal: 3.6s\tremaining: 1m 6s\n",
      "51:\tlearn: 0.8475192\ttotal: 3.67s\tremaining: 1m 6s\n",
      "52:\tlearn: 0.8416004\ttotal: 3.72s\tremaining: 1m 6s\n",
      "53:\tlearn: 0.8316882\ttotal: 3.78s\tremaining: 1m 6s\n",
      "54:\tlearn: 0.8223519\ttotal: 3.84s\tremaining: 1m 5s\n",
      "55:\tlearn: 0.8092157\ttotal: 3.9s\tremaining: 1m 5s\n",
      "56:\tlearn: 0.8040102\ttotal: 3.96s\tremaining: 1m 5s\n",
      "57:\tlearn: 0.7893382\ttotal: 4.03s\tremaining: 1m 5s\n",
      "58:\tlearn: 0.7813613\ttotal: 4.09s\tremaining: 1m 5s\n",
      "59:\tlearn: 0.7720734\ttotal: 4.15s\tremaining: 1m 5s\n",
      "60:\tlearn: 0.7646773\ttotal: 4.22s\tremaining: 1m 4s\n",
      "61:\tlearn: 0.7576953\ttotal: 4.28s\tremaining: 1m 4s\n",
      "62:\tlearn: 0.7523545\ttotal: 4.34s\tremaining: 1m 4s\n",
      "63:\tlearn: 0.7442120\ttotal: 4.41s\tremaining: 1m 4s\n",
      "64:\tlearn: 0.7363354\ttotal: 4.47s\tremaining: 1m 4s\n",
      "65:\tlearn: 0.7289712\ttotal: 4.53s\tremaining: 1m 4s\n",
      "66:\tlearn: 0.7211658\ttotal: 4.59s\tremaining: 1m 3s\n",
      "67:\tlearn: 0.7143046\ttotal: 4.65s\tremaining: 1m 3s\n",
      "68:\tlearn: 0.7096934\ttotal: 4.72s\tremaining: 1m 3s\n",
      "69:\tlearn: 0.7052536\ttotal: 4.78s\tremaining: 1m 3s\n",
      "70:\tlearn: 0.6992047\ttotal: 4.85s\tremaining: 1m 3s\n",
      "71:\tlearn: 0.6910080\ttotal: 4.92s\tremaining: 1m 3s\n",
      "72:\tlearn: 0.6856108\ttotal: 4.99s\tremaining: 1m 3s\n",
      "73:\tlearn: 0.6792984\ttotal: 5.06s\tremaining: 1m 3s\n",
      "74:\tlearn: 0.6708249\ttotal: 5.12s\tremaining: 1m 3s\n",
      "75:\tlearn: 0.6623285\ttotal: 5.19s\tremaining: 1m 3s\n",
      "76:\tlearn: 0.6546071\ttotal: 5.25s\tremaining: 1m 2s\n",
      "77:\tlearn: 0.6484859\ttotal: 5.33s\tremaining: 1m 2s\n",
      "78:\tlearn: 0.6407010\ttotal: 5.39s\tremaining: 1m 2s\n",
      "79:\tlearn: 0.6352706\ttotal: 5.45s\tremaining: 1m 2s\n",
      "80:\tlearn: 0.6292005\ttotal: 5.52s\tremaining: 1m 2s\n",
      "81:\tlearn: 0.6253473\ttotal: 5.58s\tremaining: 1m 2s\n",
      "82:\tlearn: 0.6198024\ttotal: 5.64s\tremaining: 1m 2s\n",
      "83:\tlearn: 0.6144945\ttotal: 5.71s\tremaining: 1m 2s\n",
      "84:\tlearn: 0.6088313\ttotal: 5.77s\tremaining: 1m 2s\n",
      "85:\tlearn: 0.6040300\ttotal: 5.83s\tremaining: 1m 1s\n",
      "86:\tlearn: 0.6006860\ttotal: 5.89s\tremaining: 1m 1s\n",
      "87:\tlearn: 0.5965100\ttotal: 5.96s\tremaining: 1m 1s\n",
      "88:\tlearn: 0.5935494\ttotal: 6.03s\tremaining: 1m 1s\n",
      "89:\tlearn: 0.5893658\ttotal: 6.08s\tremaining: 1m 1s\n",
      "90:\tlearn: 0.5844834\ttotal: 6.15s\tremaining: 1m 1s\n",
      "91:\tlearn: 0.5807282\ttotal: 6.22s\tremaining: 1m 1s\n",
      "92:\tlearn: 0.5756262\ttotal: 6.28s\tremaining: 1m 1s\n",
      "93:\tlearn: 0.5717731\ttotal: 6.33s\tremaining: 1m 1s\n",
      "94:\tlearn: 0.5681981\ttotal: 6.39s\tremaining: 1m\n",
      "95:\tlearn: 0.5610177\ttotal: 6.45s\tremaining: 1m\n",
      "96:\tlearn: 0.5584596\ttotal: 6.51s\tremaining: 1m\n",
      "97:\tlearn: 0.5537139\ttotal: 6.58s\tremaining: 1m\n",
      "98:\tlearn: 0.5503167\ttotal: 6.64s\tremaining: 1m\n",
      "99:\tlearn: 0.5483564\ttotal: 6.7s\tremaining: 1m\n",
      "100:\tlearn: 0.5426955\ttotal: 6.77s\tremaining: 1m\n",
      "101:\tlearn: 0.5346860\ttotal: 6.83s\tremaining: 1m\n",
      "102:\tlearn: 0.5286378\ttotal: 6.89s\tremaining: 1m\n",
      "103:\tlearn: 0.5257303\ttotal: 6.96s\tremaining: 59.9s\n",
      "104:\tlearn: 0.5216450\ttotal: 7.02s\tremaining: 59.9s\n",
      "105:\tlearn: 0.5193721\ttotal: 7.08s\tremaining: 59.8s\n",
      "106:\tlearn: 0.5153496\ttotal: 7.15s\tremaining: 59.6s\n",
      "107:\tlearn: 0.5117914\ttotal: 7.2s\tremaining: 59.5s\n",
      "108:\tlearn: 0.5080737\ttotal: 7.27s\tremaining: 59.4s\n",
      "109:\tlearn: 0.5032644\ttotal: 7.34s\tremaining: 59.4s\n",
      "110:\tlearn: 0.4990019\ttotal: 7.4s\tremaining: 59.3s\n",
      "111:\tlearn: 0.4935188\ttotal: 7.46s\tremaining: 59.1s\n",
      "112:\tlearn: 0.4894084\ttotal: 7.52s\tremaining: 59s\n",
      "113:\tlearn: 0.4853353\ttotal: 7.58s\tremaining: 59s\n",
      "114:\tlearn: 0.4803404\ttotal: 7.64s\tremaining: 58.8s\n",
      "115:\tlearn: 0.4772394\ttotal: 7.71s\tremaining: 58.8s\n",
      "116:\tlearn: 0.4746445\ttotal: 7.78s\tremaining: 58.7s\n",
      "117:\tlearn: 0.4707757\ttotal: 7.84s\tremaining: 58.6s\n",
      "118:\tlearn: 0.4689686\ttotal: 7.91s\tremaining: 58.5s\n",
      "119:\tlearn: 0.4649130\ttotal: 7.96s\tremaining: 58.4s\n",
      "120:\tlearn: 0.4628588\ttotal: 8.03s\tremaining: 58.3s\n",
      "121:\tlearn: 0.4588934\ttotal: 8.1s\tremaining: 58.3s\n",
      "122:\tlearn: 0.4543065\ttotal: 8.15s\tremaining: 58.1s\n",
      "123:\tlearn: 0.4510211\ttotal: 8.21s\tremaining: 58s\n",
      "124:\tlearn: 0.4482641\ttotal: 8.27s\tremaining: 57.9s\n",
      "125:\tlearn: 0.4459517\ttotal: 8.33s\tremaining: 57.8s\n",
      "126:\tlearn: 0.4442063\ttotal: 8.4s\tremaining: 57.7s\n",
      "127:\tlearn: 0.4416041\ttotal: 8.46s\tremaining: 57.7s\n",
      "128:\tlearn: 0.4372423\ttotal: 8.53s\tremaining: 57.6s\n",
      "129:\tlearn: 0.4352465\ttotal: 8.6s\tremaining: 57.5s\n",
      "130:\tlearn: 0.4336795\ttotal: 8.65s\tremaining: 57.4s\n",
      "131:\tlearn: 0.4302838\ttotal: 8.71s\tremaining: 57.3s\n",
      "132:\tlearn: 0.4297665\ttotal: 8.77s\tremaining: 57.2s\n",
      "133:\tlearn: 0.4281124\ttotal: 8.84s\tremaining: 57.1s\n",
      "134:\tlearn: 0.4252067\ttotal: 8.89s\tremaining: 57s\n",
      "135:\tlearn: 0.4233672\ttotal: 8.95s\tremaining: 56.8s\n",
      "136:\tlearn: 0.4212161\ttotal: 9.04s\tremaining: 56.9s\n",
      "137:\tlearn: 0.4200150\ttotal: 9.1s\tremaining: 56.8s\n",
      "138:\tlearn: 0.4176885\ttotal: 9.17s\tremaining: 56.8s\n",
      "139:\tlearn: 0.4146255\ttotal: 9.22s\tremaining: 56.7s\n",
      "140:\tlearn: 0.4119802\ttotal: 9.29s\tremaining: 56.6s\n",
      "141:\tlearn: 0.4098420\ttotal: 9.35s\tremaining: 56.5s\n",
      "142:\tlearn: 0.4058819\ttotal: 9.41s\tremaining: 56.4s\n",
      "143:\tlearn: 0.4034766\ttotal: 9.48s\tremaining: 56.4s\n",
      "144:\tlearn: 0.3994963\ttotal: 9.54s\tremaining: 56.3s\n",
      "145:\tlearn: 0.3981186\ttotal: 9.6s\tremaining: 56.2s\n",
      "146:\tlearn: 0.3952396\ttotal: 9.66s\tremaining: 56s\n",
      "147:\tlearn: 0.3929343\ttotal: 9.74s\tremaining: 56.1s\n",
      "148:\tlearn: 0.3906383\ttotal: 9.79s\tremaining: 55.9s\n",
      "149:\tlearn: 0.3871207\ttotal: 9.85s\tremaining: 55.8s\n",
      "150:\tlearn: 0.3859937\ttotal: 9.9s\tremaining: 55.7s\n",
      "151:\tlearn: 0.3840729\ttotal: 9.97s\tremaining: 55.6s\n",
      "152:\tlearn: 0.3829629\ttotal: 10s\tremaining: 55.6s\n",
      "153:\tlearn: 0.3806886\ttotal: 10.1s\tremaining: 55.5s\n",
      "154:\tlearn: 0.3780020\ttotal: 10.2s\tremaining: 55.4s\n",
      "155:\tlearn: 0.3756929\ttotal: 10.2s\tremaining: 55.3s\n",
      "156:\tlearn: 0.3746852\ttotal: 10.3s\tremaining: 55.2s\n",
      "157:\tlearn: 0.3729105\ttotal: 10.3s\tremaining: 55.1s\n",
      "158:\tlearn: 0.3698796\ttotal: 10.4s\tremaining: 55.1s\n",
      "159:\tlearn: 0.3663469\ttotal: 10.5s\tremaining: 55s\n",
      "160:\tlearn: 0.3649746\ttotal: 10.5s\tremaining: 54.8s\n",
      "161:\tlearn: 0.3623357\ttotal: 10.6s\tremaining: 54.8s\n",
      "162:\tlearn: 0.3606986\ttotal: 10.6s\tremaining: 54.7s\n",
      "163:\tlearn: 0.3593334\ttotal: 10.7s\tremaining: 54.6s\n",
      "164:\tlearn: 0.3572105\ttotal: 10.8s\tremaining: 54.5s\n",
      "165:\tlearn: 0.3542945\ttotal: 10.8s\tremaining: 54.4s\n",
      "166:\tlearn: 0.3534983\ttotal: 10.9s\tremaining: 54.3s\n",
      "167:\tlearn: 0.3509916\ttotal: 11s\tremaining: 54.3s\n",
      "168:\tlearn: 0.3497928\ttotal: 11s\tremaining: 54.2s\n",
      "169:\tlearn: 0.3476714\ttotal: 11.1s\tremaining: 54.1s\n",
      "170:\tlearn: 0.3455522\ttotal: 11.1s\tremaining: 54s\n",
      "171:\tlearn: 0.3445158\ttotal: 11.2s\tremaining: 54s\n",
      "172:\tlearn: 0.3434953\ttotal: 11.3s\tremaining: 53.8s\n",
      "173:\tlearn: 0.3421122\ttotal: 11.3s\tremaining: 53.8s\n",
      "174:\tlearn: 0.3402005\ttotal: 11.4s\tremaining: 53.7s\n",
      "175:\tlearn: 0.3379401\ttotal: 11.5s\tremaining: 53.7s\n",
      "176:\tlearn: 0.3358379\ttotal: 11.5s\tremaining: 53.6s\n",
      "177:\tlearn: 0.3338776\ttotal: 11.6s\tremaining: 53.5s\n",
      "178:\tlearn: 0.3325160\ttotal: 11.7s\tremaining: 53.5s\n",
      "179:\tlearn: 0.3314655\ttotal: 11.7s\tremaining: 53.4s\n",
      "180:\tlearn: 0.3295909\ttotal: 11.8s\tremaining: 53.3s\n",
      "181:\tlearn: 0.3282391\ttotal: 11.8s\tremaining: 53.2s\n",
      "182:\tlearn: 0.3276384\ttotal: 11.9s\tremaining: 53.1s\n",
      "183:\tlearn: 0.3259738\ttotal: 12s\tremaining: 53.1s\n",
      "184:\tlearn: 0.3250564\ttotal: 12s\tremaining: 53s\n",
      "185:\tlearn: 0.3241837\ttotal: 12.1s\tremaining: 52.9s\n",
      "186:\tlearn: 0.3220660\ttotal: 12.1s\tremaining: 52.8s\n",
      "187:\tlearn: 0.3203193\ttotal: 12.2s\tremaining: 52.7s\n",
      "188:\tlearn: 0.3194315\ttotal: 12.3s\tremaining: 52.6s\n",
      "189:\tlearn: 0.3184554\ttotal: 12.3s\tremaining: 52.5s\n",
      "190:\tlearn: 0.3165424\ttotal: 12.4s\tremaining: 52.5s\n",
      "191:\tlearn: 0.3152256\ttotal: 12.4s\tremaining: 52.4s\n",
      "192:\tlearn: 0.3133042\ttotal: 12.5s\tremaining: 52.4s\n",
      "193:\tlearn: 0.3114260\ttotal: 12.6s\tremaining: 52.3s\n",
      "194:\tlearn: 0.3106911\ttotal: 12.7s\tremaining: 52.3s\n",
      "195:\tlearn: 0.3089600\ttotal: 12.7s\tremaining: 52.2s\n",
      "196:\tlearn: 0.3079866\ttotal: 12.8s\tremaining: 52.1s\n",
      "197:\tlearn: 0.3070959\ttotal: 12.8s\tremaining: 52s\n",
      "198:\tlearn: 0.3059732\ttotal: 12.9s\tremaining: 51.9s\n",
      "199:\tlearn: 0.3040198\ttotal: 12.9s\tremaining: 51.8s\n",
      "200:\tlearn: 0.3013550\ttotal: 13s\tremaining: 51.7s\n",
      "201:\tlearn: 0.2997388\ttotal: 13.1s\tremaining: 51.7s\n",
      "202:\tlearn: 0.2979944\ttotal: 13.1s\tremaining: 51.5s\n",
      "203:\tlearn: 0.2966868\ttotal: 13.2s\tremaining: 51.5s\n",
      "204:\tlearn: 0.2959304\ttotal: 13.3s\tremaining: 51.4s\n",
      "205:\tlearn: 0.2945402\ttotal: 13.3s\tremaining: 51.3s\n",
      "206:\tlearn: 0.2928493\ttotal: 13.4s\tremaining: 51.3s\n",
      "207:\tlearn: 0.2915668\ttotal: 13.5s\tremaining: 51.2s\n",
      "208:\tlearn: 0.2905682\ttotal: 13.5s\tremaining: 51.2s\n",
      "209:\tlearn: 0.2893742\ttotal: 13.6s\tremaining: 51.1s\n",
      "210:\tlearn: 0.2885268\ttotal: 13.6s\tremaining: 51s\n",
      "211:\tlearn: 0.2873363\ttotal: 13.7s\tremaining: 50.9s\n",
      "212:\tlearn: 0.2855167\ttotal: 13.8s\tremaining: 50.9s\n",
      "213:\tlearn: 0.2829997\ttotal: 13.8s\tremaining: 50.8s\n",
      "214:\tlearn: 0.2819342\ttotal: 13.9s\tremaining: 50.8s\n",
      "215:\tlearn: 0.2805491\ttotal: 14s\tremaining: 50.7s\n",
      "216:\tlearn: 0.2787876\ttotal: 14s\tremaining: 50.6s\n",
      "217:\tlearn: 0.2777906\ttotal: 14.1s\tremaining: 50.5s\n",
      "218:\tlearn: 0.2770382\ttotal: 14.1s\tremaining: 50.5s\n",
      "219:\tlearn: 0.2760175\ttotal: 14.2s\tremaining: 50.4s\n",
      "220:\tlearn: 0.2750377\ttotal: 14.3s\tremaining: 50.3s\n",
      "221:\tlearn: 0.2729065\ttotal: 14.3s\tremaining: 50.2s\n",
      "222:\tlearn: 0.2719655\ttotal: 14.4s\tremaining: 50.1s\n",
      "223:\tlearn: 0.2703856\ttotal: 14.5s\tremaining: 50.1s\n",
      "224:\tlearn: 0.2692215\ttotal: 14.5s\tremaining: 50s\n",
      "225:\tlearn: 0.2685437\ttotal: 14.6s\tremaining: 50s\n",
      "226:\tlearn: 0.2672178\ttotal: 14.7s\tremaining: 49.9s\n",
      "227:\tlearn: 0.2661942\ttotal: 14.7s\tremaining: 49.8s\n",
      "228:\tlearn: 0.2655008\ttotal: 14.8s\tremaining: 49.8s\n",
      "229:\tlearn: 0.2646579\ttotal: 14.8s\tremaining: 49.7s\n",
      "230:\tlearn: 0.2632417\ttotal: 14.9s\tremaining: 49.6s\n",
      "231:\tlearn: 0.2618784\ttotal: 15s\tremaining: 49.5s\n",
      "232:\tlearn: 0.2610246\ttotal: 15s\tremaining: 49.4s\n",
      "233:\tlearn: 0.2601658\ttotal: 15.1s\tremaining: 49.3s\n",
      "234:\tlearn: 0.2593844\ttotal: 15.1s\tremaining: 49.3s\n",
      "235:\tlearn: 0.2587369\ttotal: 15.2s\tremaining: 49.2s\n",
      "236:\tlearn: 0.2571511\ttotal: 15.3s\tremaining: 49.2s\n",
      "237:\tlearn: 0.2555367\ttotal: 15.3s\tremaining: 49s\n",
      "238:\tlearn: 0.2545388\ttotal: 15.4s\tremaining: 49s\n",
      "239:\tlearn: 0.2539760\ttotal: 15.4s\tremaining: 48.9s\n",
      "240:\tlearn: 0.2528238\ttotal: 15.5s\tremaining: 48.8s\n",
      "241:\tlearn: 0.2513439\ttotal: 15.6s\tremaining: 48.8s\n",
      "242:\tlearn: 0.2509671\ttotal: 15.6s\tremaining: 48.7s\n",
      "243:\tlearn: 0.2498625\ttotal: 15.7s\tremaining: 48.7s\n",
      "244:\tlearn: 0.2491158\ttotal: 15.8s\tremaining: 48.6s\n",
      "245:\tlearn: 0.2482836\ttotal: 15.8s\tremaining: 48.5s\n",
      "246:\tlearn: 0.2474712\ttotal: 15.9s\tremaining: 48.5s\n",
      "247:\tlearn: 0.2467682\ttotal: 16s\tremaining: 48.4s\n",
      "248:\tlearn: 0.2467226\ttotal: 16s\tremaining: 48.3s\n",
      "249:\tlearn: 0.2462551\ttotal: 16.1s\tremaining: 48.3s\n",
      "250:\tlearn: 0.2457863\ttotal: 16.1s\tremaining: 48.2s\n",
      "251:\tlearn: 0.2450785\ttotal: 16.2s\tremaining: 48.1s\n",
      "252:\tlearn: 0.2442894\ttotal: 16.3s\tremaining: 48.1s\n",
      "253:\tlearn: 0.2431146\ttotal: 16.3s\tremaining: 48s\n",
      "254:\tlearn: 0.2411319\ttotal: 16.4s\tremaining: 47.9s\n",
      "255:\tlearn: 0.2404153\ttotal: 16.5s\tremaining: 47.9s\n",
      "256:\tlearn: 0.2396860\ttotal: 16.5s\tremaining: 47.7s\n",
      "257:\tlearn: 0.2387142\ttotal: 16.6s\tremaining: 47.6s\n",
      "258:\tlearn: 0.2376591\ttotal: 16.6s\tremaining: 47.6s\n",
      "259:\tlearn: 0.2367486\ttotal: 16.7s\tremaining: 47.5s\n",
      "260:\tlearn: 0.2359983\ttotal: 16.7s\tremaining: 47.4s\n",
      "261:\tlearn: 0.2352641\ttotal: 16.8s\tremaining: 47.3s\n",
      "262:\tlearn: 0.2345283\ttotal: 16.9s\tremaining: 47.3s\n",
      "263:\tlearn: 0.2334127\ttotal: 16.9s\tremaining: 47.2s\n",
      "264:\tlearn: 0.2316757\ttotal: 17s\tremaining: 47.2s\n",
      "265:\tlearn: 0.2306098\ttotal: 17.1s\tremaining: 47.1s\n",
      "266:\tlearn: 0.2294691\ttotal: 17.1s\tremaining: 47s\n",
      "267:\tlearn: 0.2286839\ttotal: 17.2s\tremaining: 47s\n",
      "268:\tlearn: 0.2281744\ttotal: 17.3s\tremaining: 46.9s\n",
      "269:\tlearn: 0.2278821\ttotal: 17.3s\tremaining: 46.8s\n",
      "270:\tlearn: 0.2267139\ttotal: 17.4s\tremaining: 46.8s\n",
      "271:\tlearn: 0.2261750\ttotal: 17.5s\tremaining: 46.7s\n",
      "272:\tlearn: 0.2246164\ttotal: 17.5s\tremaining: 46.6s\n",
      "273:\tlearn: 0.2236661\ttotal: 17.6s\tremaining: 46.6s\n",
      "274:\tlearn: 0.2225581\ttotal: 17.6s\tremaining: 46.5s\n",
      "275:\tlearn: 0.2216728\ttotal: 17.7s\tremaining: 46.4s\n",
      "276:\tlearn: 0.2206491\ttotal: 17.8s\tremaining: 46.4s\n",
      "277:\tlearn: 0.2196815\ttotal: 17.8s\tremaining: 46.3s\n",
      "278:\tlearn: 0.2191453\ttotal: 17.9s\tremaining: 46.2s\n",
      "279:\tlearn: 0.2180586\ttotal: 18s\tremaining: 46.2s\n",
      "280:\tlearn: 0.2173178\ttotal: 18s\tremaining: 46.1s\n",
      "281:\tlearn: 0.2166495\ttotal: 18.1s\tremaining: 46s\n",
      "282:\tlearn: 0.2162082\ttotal: 18.1s\tremaining: 46s\n",
      "283:\tlearn: 0.2154330\ttotal: 18.2s\tremaining: 45.9s\n",
      "284:\tlearn: 0.2148963\ttotal: 18.3s\tremaining: 45.8s\n",
      "285:\tlearn: 0.2138310\ttotal: 18.3s\tremaining: 45.7s\n",
      "286:\tlearn: 0.2129289\ttotal: 18.4s\tremaining: 45.6s\n",
      "287:\tlearn: 0.2121304\ttotal: 18.4s\tremaining: 45.5s\n",
      "288:\tlearn: 0.2114507\ttotal: 18.5s\tremaining: 45.5s\n",
      "289:\tlearn: 0.2103979\ttotal: 18.5s\tremaining: 45.4s\n",
      "290:\tlearn: 0.2099358\ttotal: 18.6s\tremaining: 45.4s\n",
      "291:\tlearn: 0.2090788\ttotal: 18.7s\tremaining: 45.3s\n",
      "292:\tlearn: 0.2078595\ttotal: 18.8s\tremaining: 45.3s\n",
      "293:\tlearn: 0.2075532\ttotal: 18.8s\tremaining: 45.2s\n",
      "294:\tlearn: 0.2072660\ttotal: 18.9s\tremaining: 45.1s\n",
      "295:\tlearn: 0.2064189\ttotal: 18.9s\tremaining: 45s\n",
      "296:\tlearn: 0.2059015\ttotal: 19s\tremaining: 45s\n",
      "297:\tlearn: 0.2051882\ttotal: 19.1s\tremaining: 44.9s\n",
      "298:\tlearn: 0.2040940\ttotal: 19.1s\tremaining: 44.8s\n",
      "299:\tlearn: 0.2037543\ttotal: 19.2s\tremaining: 44.7s\n",
      "300:\tlearn: 0.2019686\ttotal: 19.3s\tremaining: 44.7s\n",
      "301:\tlearn: 0.2011689\ttotal: 19.3s\tremaining: 44.7s\n",
      "302:\tlearn: 0.2004460\ttotal: 19.4s\tremaining: 44.6s\n",
      "303:\tlearn: 0.1999419\ttotal: 19.5s\tremaining: 44.6s\n",
      "304:\tlearn: 0.1996432\ttotal: 19.6s\tremaining: 44.6s\n",
      "305:\tlearn: 0.1988854\ttotal: 19.6s\tremaining: 44.4s\n",
      "306:\tlearn: 0.1983783\ttotal: 19.7s\tremaining: 44.4s\n",
      "307:\tlearn: 0.1976493\ttotal: 19.7s\tremaining: 44.3s\n",
      "308:\tlearn: 0.1967828\ttotal: 19.8s\tremaining: 44.2s\n",
      "309:\tlearn: 0.1954893\ttotal: 19.9s\tremaining: 44.2s\n",
      "310:\tlearn: 0.1943093\ttotal: 19.9s\tremaining: 44.1s\n",
      "311:\tlearn: 0.1936687\ttotal: 20s\tremaining: 44s\n",
      "312:\tlearn: 0.1929581\ttotal: 20s\tremaining: 44s\n",
      "313:\tlearn: 0.1926595\ttotal: 20.1s\tremaining: 43.9s\n",
      "314:\tlearn: 0.1917264\ttotal: 20.1s\tremaining: 43.8s\n",
      "315:\tlearn: 0.1910917\ttotal: 20.2s\tremaining: 43.7s\n",
      "316:\tlearn: 0.1907461\ttotal: 20.3s\tremaining: 43.7s\n",
      "317:\tlearn: 0.1904304\ttotal: 20.3s\tremaining: 43.6s\n",
      "318:\tlearn: 0.1895433\ttotal: 20.4s\tremaining: 43.5s\n",
      "319:\tlearn: 0.1887577\ttotal: 20.4s\tremaining: 43.4s\n",
      "320:\tlearn: 0.1881427\ttotal: 20.5s\tremaining: 43.3s\n",
      "321:\tlearn: 0.1873774\ttotal: 20.6s\tremaining: 43.3s\n",
      "322:\tlearn: 0.1869346\ttotal: 20.6s\tremaining: 43.2s\n",
      "323:\tlearn: 0.1864490\ttotal: 20.7s\tremaining: 43.1s\n",
      "324:\tlearn: 0.1861393\ttotal: 20.7s\tremaining: 43.1s\n",
      "325:\tlearn: 0.1856946\ttotal: 20.8s\tremaining: 43s\n",
      "326:\tlearn: 0.1853271\ttotal: 20.8s\tremaining: 42.9s\n",
      "327:\tlearn: 0.1847398\ttotal: 20.9s\tremaining: 42.8s\n",
      "328:\tlearn: 0.1844230\ttotal: 21s\tremaining: 42.8s\n",
      "329:\tlearn: 0.1837499\ttotal: 21s\tremaining: 42.7s\n",
      "330:\tlearn: 0.1828080\ttotal: 21.1s\tremaining: 42.6s\n",
      "331:\tlearn: 0.1823054\ttotal: 21.1s\tremaining: 42.5s\n",
      "332:\tlearn: 0.1814781\ttotal: 21.2s\tremaining: 42.5s\n",
      "333:\tlearn: 0.1810895\ttotal: 21.3s\tremaining: 42.4s\n",
      "334:\tlearn: 0.1808371\ttotal: 21.3s\tremaining: 42.3s\n",
      "335:\tlearn: 0.1805120\ttotal: 21.4s\tremaining: 42.3s\n",
      "336:\tlearn: 0.1799364\ttotal: 21.4s\tremaining: 42.2s\n",
      "337:\tlearn: 0.1792023\ttotal: 21.5s\tremaining: 42.1s\n",
      "338:\tlearn: 0.1787763\ttotal: 21.6s\tremaining: 42.1s\n",
      "339:\tlearn: 0.1776828\ttotal: 21.6s\tremaining: 42s\n",
      "340:\tlearn: 0.1773627\ttotal: 21.7s\tremaining: 41.9s\n",
      "341:\tlearn: 0.1770864\ttotal: 21.8s\tremaining: 41.9s\n",
      "342:\tlearn: 0.1762885\ttotal: 21.8s\tremaining: 41.8s\n",
      "343:\tlearn: 0.1757561\ttotal: 21.9s\tremaining: 41.7s\n",
      "344:\tlearn: 0.1748250\ttotal: 22s\tremaining: 41.7s\n",
      "345:\tlearn: 0.1743008\ttotal: 22s\tremaining: 41.6s\n",
      "346:\tlearn: 0.1739123\ttotal: 22.1s\tremaining: 41.5s\n",
      "347:\tlearn: 0.1735382\ttotal: 22.1s\tremaining: 41.4s\n",
      "348:\tlearn: 0.1732447\ttotal: 22.2s\tremaining: 41.4s\n",
      "349:\tlearn: 0.1723530\ttotal: 22.2s\tremaining: 41.3s\n",
      "350:\tlearn: 0.1720410\ttotal: 22.3s\tremaining: 41.2s\n",
      "351:\tlearn: 0.1715613\ttotal: 22.4s\tremaining: 41.1s\n",
      "352:\tlearn: 0.1711409\ttotal: 22.4s\tremaining: 41.1s\n",
      "353:\tlearn: 0.1705893\ttotal: 22.5s\tremaining: 41s\n",
      "354:\tlearn: 0.1703107\ttotal: 22.5s\tremaining: 41s\n",
      "355:\tlearn: 0.1694418\ttotal: 22.6s\tremaining: 40.9s\n",
      "356:\tlearn: 0.1689051\ttotal: 22.7s\tremaining: 40.8s\n",
      "357:\tlearn: 0.1682556\ttotal: 22.7s\tremaining: 40.7s\n",
      "358:\tlearn: 0.1680886\ttotal: 22.8s\tremaining: 40.7s\n",
      "359:\tlearn: 0.1676845\ttotal: 22.8s\tremaining: 40.6s\n",
      "360:\tlearn: 0.1674568\ttotal: 22.9s\tremaining: 40.5s\n",
      "361:\tlearn: 0.1671346\ttotal: 23s\tremaining: 40.5s\n",
      "362:\tlearn: 0.1665482\ttotal: 23s\tremaining: 40.4s\n",
      "363:\tlearn: 0.1661415\ttotal: 23.1s\tremaining: 40.3s\n",
      "364:\tlearn: 0.1656631\ttotal: 23.1s\tremaining: 40.3s\n",
      "365:\tlearn: 0.1651531\ttotal: 23.2s\tremaining: 40.2s\n",
      "366:\tlearn: 0.1648708\ttotal: 23.3s\tremaining: 40.1s\n",
      "367:\tlearn: 0.1644210\ttotal: 23.3s\tremaining: 40s\n",
      "368:\tlearn: 0.1640735\ttotal: 23.4s\tremaining: 40s\n",
      "369:\tlearn: 0.1635148\ttotal: 23.4s\tremaining: 39.9s\n",
      "370:\tlearn: 0.1632764\ttotal: 23.5s\tremaining: 39.8s\n",
      "371:\tlearn: 0.1628957\ttotal: 23.6s\tremaining: 39.8s\n",
      "372:\tlearn: 0.1625759\ttotal: 23.6s\tremaining: 39.7s\n",
      "373:\tlearn: 0.1621640\ttotal: 23.7s\tremaining: 39.7s\n",
      "374:\tlearn: 0.1614292\ttotal: 23.8s\tremaining: 39.6s\n",
      "375:\tlearn: 0.1608640\ttotal: 23.8s\tremaining: 39.5s\n",
      "376:\tlearn: 0.1600920\ttotal: 23.9s\tremaining: 39.4s\n",
      "377:\tlearn: 0.1594096\ttotal: 23.9s\tremaining: 39.4s\n",
      "378:\tlearn: 0.1590966\ttotal: 24s\tremaining: 39.3s\n",
      "379:\tlearn: 0.1589152\ttotal: 24.1s\tremaining: 39.3s\n",
      "380:\tlearn: 0.1585085\ttotal: 24.1s\tremaining: 39.2s\n",
      "381:\tlearn: 0.1581972\ttotal: 24.2s\tremaining: 39.1s\n",
      "382:\tlearn: 0.1576701\ttotal: 24.2s\tremaining: 39s\n",
      "383:\tlearn: 0.1573104\ttotal: 24.3s\tremaining: 39s\n",
      "384:\tlearn: 0.1571349\ttotal: 24.4s\tremaining: 38.9s\n",
      "385:\tlearn: 0.1561381\ttotal: 24.4s\tremaining: 38.9s\n",
      "386:\tlearn: 0.1558629\ttotal: 24.5s\tremaining: 38.8s\n",
      "387:\tlearn: 0.1556129\ttotal: 24.5s\tremaining: 38.7s\n",
      "388:\tlearn: 0.1548140\ttotal: 24.6s\tremaining: 38.6s\n",
      "389:\tlearn: 0.1543802\ttotal: 24.7s\tremaining: 38.6s\n",
      "390:\tlearn: 0.1537737\ttotal: 24.7s\tremaining: 38.5s\n",
      "391:\tlearn: 0.1535653\ttotal: 24.8s\tremaining: 38.4s\n",
      "392:\tlearn: 0.1533381\ttotal: 24.8s\tremaining: 38.4s\n",
      "393:\tlearn: 0.1529719\ttotal: 24.9s\tremaining: 38.3s\n",
      "394:\tlearn: 0.1525634\ttotal: 25s\tremaining: 38.2s\n",
      "395:\tlearn: 0.1518684\ttotal: 25s\tremaining: 38.2s\n",
      "396:\tlearn: 0.1517679\ttotal: 25.1s\tremaining: 38.1s\n",
      "397:\tlearn: 0.1514121\ttotal: 25.2s\tremaining: 38.1s\n",
      "398:\tlearn: 0.1506631\ttotal: 25.2s\tremaining: 38s\n",
      "399:\tlearn: 0.1503675\ttotal: 25.3s\tremaining: 37.9s\n",
      "400:\tlearn: 0.1498955\ttotal: 25.3s\tremaining: 37.9s\n",
      "401:\tlearn: 0.1496346\ttotal: 25.4s\tremaining: 37.8s\n",
      "402:\tlearn: 0.1492701\ttotal: 25.5s\tremaining: 37.7s\n",
      "403:\tlearn: 0.1486538\ttotal: 25.5s\tremaining: 37.6s\n",
      "404:\tlearn: 0.1479824\ttotal: 25.6s\tremaining: 37.6s\n",
      "405:\tlearn: 0.1475747\ttotal: 25.6s\tremaining: 37.5s\n",
      "406:\tlearn: 0.1471131\ttotal: 25.7s\tremaining: 37.4s\n",
      "407:\tlearn: 0.1469025\ttotal: 25.8s\tremaining: 37.4s\n",
      "408:\tlearn: 0.1468196\ttotal: 25.8s\tremaining: 37.3s\n",
      "409:\tlearn: 0.1466612\ttotal: 25.9s\tremaining: 37.2s\n",
      "410:\tlearn: 0.1465163\ttotal: 25.9s\tremaining: 37.2s\n",
      "411:\tlearn: 0.1459392\ttotal: 26s\tremaining: 37.1s\n",
      "412:\tlearn: 0.1457168\ttotal: 26s\tremaining: 37s\n",
      "413:\tlearn: 0.1453032\ttotal: 26.1s\tremaining: 37s\n",
      "414:\tlearn: 0.1447008\ttotal: 26.2s\tremaining: 36.9s\n",
      "415:\tlearn: 0.1444560\ttotal: 26.2s\tremaining: 36.8s\n",
      "416:\tlearn: 0.1440264\ttotal: 26.3s\tremaining: 36.7s\n",
      "417:\tlearn: 0.1434777\ttotal: 26.3s\tremaining: 36.7s\n",
      "418:\tlearn: 0.1426896\ttotal: 26.4s\tremaining: 36.6s\n",
      "419:\tlearn: 0.1423803\ttotal: 26.5s\tremaining: 36.5s\n",
      "420:\tlearn: 0.1421577\ttotal: 26.5s\tremaining: 36.5s\n",
      "421:\tlearn: 0.1417657\ttotal: 26.6s\tremaining: 36.4s\n",
      "422:\tlearn: 0.1414371\ttotal: 26.6s\tremaining: 36.3s\n",
      "423:\tlearn: 0.1412649\ttotal: 26.7s\tremaining: 36.3s\n",
      "424:\tlearn: 0.1406625\ttotal: 26.8s\tremaining: 36.2s\n",
      "425:\tlearn: 0.1399817\ttotal: 26.8s\tremaining: 36.1s\n",
      "426:\tlearn: 0.1397777\ttotal: 26.9s\tremaining: 36.1s\n",
      "427:\tlearn: 0.1393879\ttotal: 26.9s\tremaining: 36s\n",
      "428:\tlearn: 0.1387613\ttotal: 27s\tremaining: 36s\n",
      "429:\tlearn: 0.1381389\ttotal: 27.1s\tremaining: 35.9s\n",
      "430:\tlearn: 0.1378681\ttotal: 27.1s\tremaining: 35.8s\n",
      "431:\tlearn: 0.1375094\ttotal: 27.2s\tremaining: 35.7s\n",
      "432:\tlearn: 0.1373869\ttotal: 27.3s\tremaining: 35.7s\n",
      "433:\tlearn: 0.1371598\ttotal: 27.3s\tremaining: 35.6s\n",
      "434:\tlearn: 0.1369529\ttotal: 27.4s\tremaining: 35.6s\n",
      "435:\tlearn: 0.1365714\ttotal: 27.4s\tremaining: 35.5s\n",
      "436:\tlearn: 0.1361585\ttotal: 27.5s\tremaining: 35.4s\n",
      "437:\tlearn: 0.1358691\ttotal: 27.6s\tremaining: 35.4s\n",
      "438:\tlearn: 0.1356799\ttotal: 27.6s\tremaining: 35.3s\n",
      "439:\tlearn: 0.1351754\ttotal: 27.7s\tremaining: 35.2s\n",
      "440:\tlearn: 0.1350854\ttotal: 27.7s\tremaining: 35.2s\n",
      "441:\tlearn: 0.1349222\ttotal: 27.8s\tremaining: 35.1s\n",
      "442:\tlearn: 0.1347562\ttotal: 27.9s\tremaining: 35s\n",
      "443:\tlearn: 0.1343572\ttotal: 27.9s\tremaining: 35s\n",
      "444:\tlearn: 0.1340385\ttotal: 28s\tremaining: 34.9s\n",
      "445:\tlearn: 0.1337248\ttotal: 28.1s\tremaining: 34.8s\n",
      "446:\tlearn: 0.1334725\ttotal: 28.1s\tremaining: 34.8s\n",
      "447:\tlearn: 0.1332424\ttotal: 28.2s\tremaining: 34.7s\n",
      "448:\tlearn: 0.1331141\ttotal: 28.2s\tremaining: 34.6s\n",
      "449:\tlearn: 0.1326875\ttotal: 28.3s\tremaining: 34.6s\n",
      "450:\tlearn: 0.1321985\ttotal: 28.4s\tremaining: 34.5s\n",
      "451:\tlearn: 0.1317207\ttotal: 28.4s\tremaining: 34.4s\n",
      "452:\tlearn: 0.1311784\ttotal: 28.5s\tremaining: 34.4s\n",
      "453:\tlearn: 0.1307934\ttotal: 28.5s\tremaining: 34.3s\n",
      "454:\tlearn: 0.1302092\ttotal: 28.6s\tremaining: 34.3s\n",
      "455:\tlearn: 0.1301161\ttotal: 28.7s\tremaining: 34.2s\n",
      "456:\tlearn: 0.1299214\ttotal: 28.7s\tremaining: 34.1s\n",
      "457:\tlearn: 0.1294663\ttotal: 28.8s\tremaining: 34.1s\n",
      "458:\tlearn: 0.1293992\ttotal: 28.8s\tremaining: 34s\n",
      "459:\tlearn: 0.1289122\ttotal: 28.9s\tremaining: 33.9s\n",
      "460:\tlearn: 0.1285480\ttotal: 29s\tremaining: 33.9s\n",
      "461:\tlearn: 0.1283661\ttotal: 29s\tremaining: 33.8s\n",
      "462:\tlearn: 0.1281811\ttotal: 29.1s\tremaining: 33.7s\n",
      "463:\tlearn: 0.1280938\ttotal: 29.1s\tremaining: 33.7s\n",
      "464:\tlearn: 0.1279227\ttotal: 29.2s\tremaining: 33.6s\n",
      "465:\tlearn: 0.1277147\ttotal: 29.3s\tremaining: 33.5s\n",
      "466:\tlearn: 0.1271023\ttotal: 29.3s\tremaining: 33.5s\n",
      "467:\tlearn: 0.1269428\ttotal: 29.4s\tremaining: 33.4s\n",
      "468:\tlearn: 0.1267271\ttotal: 29.4s\tremaining: 33.3s\n",
      "469:\tlearn: 0.1262532\ttotal: 29.5s\tremaining: 33.3s\n",
      "470:\tlearn: 0.1260178\ttotal: 29.6s\tremaining: 33.2s\n",
      "471:\tlearn: 0.1255721\ttotal: 29.6s\tremaining: 33.2s\n",
      "472:\tlearn: 0.1253669\ttotal: 29.7s\tremaining: 33.1s\n",
      "473:\tlearn: 0.1250778\ttotal: 29.8s\tremaining: 33s\n",
      "474:\tlearn: 0.1248440\ttotal: 29.8s\tremaining: 33s\n",
      "475:\tlearn: 0.1244629\ttotal: 29.9s\tremaining: 32.9s\n",
      "476:\tlearn: 0.1239004\ttotal: 30s\tremaining: 32.9s\n",
      "477:\tlearn: 0.1235707\ttotal: 30s\tremaining: 32.8s\n",
      "478:\tlearn: 0.1233639\ttotal: 30.1s\tremaining: 32.7s\n",
      "479:\tlearn: 0.1230430\ttotal: 30.2s\tremaining: 32.7s\n",
      "480:\tlearn: 0.1223280\ttotal: 30.2s\tremaining: 32.6s\n",
      "481:\tlearn: 0.1219683\ttotal: 30.3s\tremaining: 32.5s\n",
      "482:\tlearn: 0.1217828\ttotal: 30.3s\tremaining: 32.5s\n",
      "483:\tlearn: 0.1214992\ttotal: 30.4s\tremaining: 32.4s\n",
      "484:\tlearn: 0.1211590\ttotal: 30.4s\tremaining: 32.3s\n",
      "485:\tlearn: 0.1206864\ttotal: 30.5s\tremaining: 32.3s\n",
      "486:\tlearn: 0.1205564\ttotal: 30.6s\tremaining: 32.2s\n",
      "487:\tlearn: 0.1204102\ttotal: 30.6s\tremaining: 32.1s\n",
      "488:\tlearn: 0.1202820\ttotal: 30.7s\tremaining: 32.1s\n",
      "489:\tlearn: 0.1200088\ttotal: 30.8s\tremaining: 32s\n",
      "490:\tlearn: 0.1199030\ttotal: 30.8s\tremaining: 31.9s\n",
      "491:\tlearn: 0.1193797\ttotal: 30.9s\tremaining: 31.9s\n",
      "492:\tlearn: 0.1193059\ttotal: 30.9s\tremaining: 31.8s\n",
      "493:\tlearn: 0.1189926\ttotal: 31s\tremaining: 31.8s\n",
      "494:\tlearn: 0.1186853\ttotal: 31.1s\tremaining: 31.7s\n",
      "495:\tlearn: 0.1185273\ttotal: 31.1s\tremaining: 31.6s\n",
      "496:\tlearn: 0.1180366\ttotal: 31.2s\tremaining: 31.6s\n",
      "497:\tlearn: 0.1177100\ttotal: 31.2s\tremaining: 31.5s\n",
      "498:\tlearn: 0.1172292\ttotal: 31.3s\tremaining: 31.4s\n",
      "499:\tlearn: 0.1168672\ttotal: 31.4s\tremaining: 31.4s\n",
      "500:\tlearn: 0.1165854\ttotal: 31.4s\tremaining: 31.3s\n",
      "501:\tlearn: 0.1161297\ttotal: 31.5s\tremaining: 31.2s\n",
      "502:\tlearn: 0.1158530\ttotal: 31.5s\tremaining: 31.2s\n",
      "503:\tlearn: 0.1156944\ttotal: 31.6s\tremaining: 31.1s\n",
      "504:\tlearn: 0.1153238\ttotal: 31.7s\tremaining: 31s\n",
      "505:\tlearn: 0.1151793\ttotal: 31.7s\tremaining: 31s\n",
      "506:\tlearn: 0.1149547\ttotal: 31.8s\tremaining: 30.9s\n",
      "507:\tlearn: 0.1147552\ttotal: 31.8s\tremaining: 30.8s\n",
      "508:\tlearn: 0.1145427\ttotal: 31.9s\tremaining: 30.8s\n",
      "509:\tlearn: 0.1140682\ttotal: 32s\tremaining: 30.7s\n",
      "510:\tlearn: 0.1138895\ttotal: 32s\tremaining: 30.6s\n",
      "511:\tlearn: 0.1137689\ttotal: 32.1s\tremaining: 30.6s\n",
      "512:\tlearn: 0.1135104\ttotal: 32.2s\tremaining: 30.5s\n",
      "513:\tlearn: 0.1130995\ttotal: 32.2s\tremaining: 30.5s\n",
      "514:\tlearn: 0.1129364\ttotal: 32.3s\tremaining: 30.4s\n",
      "515:\tlearn: 0.1126253\ttotal: 32.3s\tremaining: 30.3s\n",
      "516:\tlearn: 0.1125172\ttotal: 32.4s\tremaining: 30.3s\n",
      "517:\tlearn: 0.1124453\ttotal: 32.4s\tremaining: 30.2s\n",
      "518:\tlearn: 0.1123779\ttotal: 32.5s\tremaining: 30.1s\n",
      "519:\tlearn: 0.1122192\ttotal: 32.6s\tremaining: 30.1s\n",
      "520:\tlearn: 0.1118059\ttotal: 32.6s\tremaining: 30s\n",
      "521:\tlearn: 0.1115237\ttotal: 32.7s\tremaining: 29.9s\n",
      "522:\tlearn: 0.1110783\ttotal: 32.8s\tremaining: 29.9s\n",
      "523:\tlearn: 0.1109605\ttotal: 32.8s\tremaining: 29.8s\n",
      "524:\tlearn: 0.1108514\ttotal: 32.9s\tremaining: 29.7s\n",
      "525:\tlearn: 0.1106707\ttotal: 32.9s\tremaining: 29.7s\n",
      "526:\tlearn: 0.1103764\ttotal: 33s\tremaining: 29.6s\n",
      "527:\tlearn: 0.1100153\ttotal: 33.1s\tremaining: 29.6s\n",
      "528:\tlearn: 0.1097529\ttotal: 33.1s\tremaining: 29.5s\n",
      "529:\tlearn: 0.1096433\ttotal: 33.2s\tremaining: 29.4s\n",
      "530:\tlearn: 0.1094317\ttotal: 33.3s\tremaining: 29.4s\n",
      "531:\tlearn: 0.1090306\ttotal: 33.3s\tremaining: 29.3s\n",
      "532:\tlearn: 0.1089300\ttotal: 33.4s\tremaining: 29.3s\n",
      "533:\tlearn: 0.1084603\ttotal: 33.5s\tremaining: 29.2s\n",
      "534:\tlearn: 0.1080256\ttotal: 33.5s\tremaining: 29.1s\n",
      "535:\tlearn: 0.1079374\ttotal: 33.6s\tremaining: 29.1s\n",
      "536:\tlearn: 0.1078562\ttotal: 33.6s\tremaining: 29s\n",
      "537:\tlearn: 0.1076392\ttotal: 33.7s\tremaining: 28.9s\n",
      "538:\tlearn: 0.1073207\ttotal: 33.8s\tremaining: 28.9s\n",
      "539:\tlearn: 0.1071167\ttotal: 33.8s\tremaining: 28.8s\n",
      "540:\tlearn: 0.1066577\ttotal: 33.9s\tremaining: 28.7s\n",
      "541:\tlearn: 0.1064588\ttotal: 33.9s\tremaining: 28.7s\n",
      "542:\tlearn: 0.1061569\ttotal: 34s\tremaining: 28.6s\n",
      "543:\tlearn: 0.1060836\ttotal: 34.1s\tremaining: 28.6s\n",
      "544:\tlearn: 0.1056433\ttotal: 34.1s\tremaining: 28.5s\n",
      "545:\tlearn: 0.1054620\ttotal: 34.2s\tremaining: 28.4s\n",
      "546:\tlearn: 0.1051243\ttotal: 34.3s\tremaining: 28.4s\n",
      "547:\tlearn: 0.1050456\ttotal: 34.3s\tremaining: 28.3s\n",
      "548:\tlearn: 0.1046355\ttotal: 34.4s\tremaining: 28.2s\n",
      "549:\tlearn: 0.1043461\ttotal: 34.4s\tremaining: 28.2s\n",
      "550:\tlearn: 0.1042357\ttotal: 34.5s\tremaining: 28.1s\n",
      "551:\tlearn: 0.1040692\ttotal: 34.5s\tremaining: 28s\n",
      "552:\tlearn: 0.1039384\ttotal: 34.6s\tremaining: 28s\n",
      "553:\tlearn: 0.1034723\ttotal: 34.7s\tremaining: 27.9s\n",
      "554:\tlearn: 0.1033243\ttotal: 34.8s\tremaining: 27.9s\n",
      "555:\tlearn: 0.1030526\ttotal: 34.8s\tremaining: 27.8s\n",
      "556:\tlearn: 0.1029702\ttotal: 34.9s\tremaining: 27.7s\n",
      "557:\tlearn: 0.1028690\ttotal: 34.9s\tremaining: 27.7s\n",
      "558:\tlearn: 0.1027814\ttotal: 35s\tremaining: 27.6s\n",
      "559:\tlearn: 0.1025881\ttotal: 35.1s\tremaining: 27.5s\n",
      "560:\tlearn: 0.1022451\ttotal: 35.1s\tremaining: 27.5s\n",
      "561:\tlearn: 0.1020908\ttotal: 35.2s\tremaining: 27.4s\n",
      "562:\tlearn: 0.1019295\ttotal: 35.2s\tremaining: 27.4s\n",
      "563:\tlearn: 0.1016982\ttotal: 35.3s\tremaining: 27.3s\n",
      "564:\tlearn: 0.1015437\ttotal: 35.4s\tremaining: 27.2s\n",
      "565:\tlearn: 0.1014656\ttotal: 35.5s\tremaining: 27.2s\n",
      "566:\tlearn: 0.1013155\ttotal: 35.5s\tremaining: 27.1s\n",
      "567:\tlearn: 0.1010769\ttotal: 35.6s\tremaining: 27.1s\n",
      "568:\tlearn: 0.1010215\ttotal: 35.6s\tremaining: 27s\n",
      "569:\tlearn: 0.1007118\ttotal: 35.7s\tremaining: 26.9s\n",
      "570:\tlearn: 0.1004479\ttotal: 35.8s\tremaining: 26.9s\n",
      "571:\tlearn: 0.1000205\ttotal: 35.8s\tremaining: 26.8s\n",
      "572:\tlearn: 0.0997318\ttotal: 35.9s\tremaining: 26.7s\n",
      "573:\tlearn: 0.0995955\ttotal: 35.9s\tremaining: 26.7s\n",
      "574:\tlearn: 0.0992109\ttotal: 36s\tremaining: 26.6s\n",
      "575:\tlearn: 0.0990008\ttotal: 36.1s\tremaining: 26.6s\n",
      "576:\tlearn: 0.0986551\ttotal: 36.1s\tremaining: 26.5s\n",
      "577:\tlearn: 0.0983633\ttotal: 36.2s\tremaining: 26.4s\n",
      "578:\tlearn: 0.0982665\ttotal: 36.3s\tremaining: 26.4s\n",
      "579:\tlearn: 0.0980747\ttotal: 36.3s\tremaining: 26.3s\n",
      "580:\tlearn: 0.0977952\ttotal: 36.4s\tremaining: 26.2s\n",
      "581:\tlearn: 0.0974166\ttotal: 36.4s\tremaining: 26.2s\n",
      "582:\tlearn: 0.0973320\ttotal: 36.5s\tremaining: 26.1s\n",
      "583:\tlearn: 0.0972070\ttotal: 36.6s\tremaining: 26s\n",
      "584:\tlearn: 0.0970975\ttotal: 36.6s\tremaining: 26s\n",
      "585:\tlearn: 0.0967512\ttotal: 36.7s\tremaining: 25.9s\n",
      "586:\tlearn: 0.0964363\ttotal: 36.8s\tremaining: 25.9s\n",
      "587:\tlearn: 0.0961574\ttotal: 36.8s\tremaining: 25.8s\n",
      "588:\tlearn: 0.0959629\ttotal: 36.9s\tremaining: 25.7s\n",
      "589:\tlearn: 0.0958921\ttotal: 36.9s\tremaining: 25.7s\n",
      "590:\tlearn: 0.0956113\ttotal: 37s\tremaining: 25.6s\n",
      "591:\tlearn: 0.0952985\ttotal: 37.1s\tremaining: 25.5s\n",
      "592:\tlearn: 0.0950622\ttotal: 37.1s\tremaining: 25.5s\n",
      "593:\tlearn: 0.0948799\ttotal: 37.2s\tremaining: 25.4s\n",
      "594:\tlearn: 0.0945676\ttotal: 37.2s\tremaining: 25.3s\n",
      "595:\tlearn: 0.0945243\ttotal: 37.3s\tremaining: 25.3s\n",
      "596:\tlearn: 0.0942947\ttotal: 37.4s\tremaining: 25.2s\n",
      "597:\tlearn: 0.0939307\ttotal: 37.4s\tremaining: 25.2s\n",
      "598:\tlearn: 0.0936386\ttotal: 37.5s\tremaining: 25.1s\n",
      "599:\tlearn: 0.0934760\ttotal: 37.6s\tremaining: 25s\n",
      "600:\tlearn: 0.0932769\ttotal: 37.6s\tremaining: 25s\n",
      "601:\tlearn: 0.0931503\ttotal: 37.7s\tremaining: 24.9s\n",
      "602:\tlearn: 0.0929269\ttotal: 37.8s\tremaining: 24.9s\n",
      "603:\tlearn: 0.0928102\ttotal: 37.8s\tremaining: 24.8s\n",
      "604:\tlearn: 0.0927735\ttotal: 37.9s\tremaining: 24.7s\n",
      "605:\tlearn: 0.0926944\ttotal: 37.9s\tremaining: 24.7s\n",
      "606:\tlearn: 0.0926459\ttotal: 38s\tremaining: 24.6s\n",
      "607:\tlearn: 0.0925800\ttotal: 38.1s\tremaining: 24.5s\n",
      "608:\tlearn: 0.0925209\ttotal: 38.1s\tremaining: 24.5s\n",
      "609:\tlearn: 0.0923515\ttotal: 38.2s\tremaining: 24.4s\n",
      "610:\tlearn: 0.0921216\ttotal: 38.3s\tremaining: 24.4s\n",
      "611:\tlearn: 0.0918112\ttotal: 38.3s\tremaining: 24.3s\n",
      "612:\tlearn: 0.0915480\ttotal: 38.4s\tremaining: 24.2s\n",
      "613:\tlearn: 0.0915140\ttotal: 38.5s\tremaining: 24.2s\n",
      "614:\tlearn: 0.0912929\ttotal: 38.5s\tremaining: 24.1s\n",
      "615:\tlearn: 0.0911756\ttotal: 38.6s\tremaining: 24s\n",
      "616:\tlearn: 0.0911290\ttotal: 38.6s\tremaining: 24s\n",
      "617:\tlearn: 0.0909598\ttotal: 38.7s\tremaining: 23.9s\n",
      "618:\tlearn: 0.0908363\ttotal: 38.8s\tremaining: 23.9s\n",
      "619:\tlearn: 0.0907158\ttotal: 38.8s\tremaining: 23.8s\n",
      "620:\tlearn: 0.0906642\ttotal: 38.9s\tremaining: 23.7s\n",
      "621:\tlearn: 0.0905709\ttotal: 38.9s\tremaining: 23.7s\n",
      "622:\tlearn: 0.0905366\ttotal: 39s\tremaining: 23.6s\n",
      "623:\tlearn: 0.0903106\ttotal: 39.1s\tremaining: 23.5s\n",
      "624:\tlearn: 0.0901782\ttotal: 39.2s\tremaining: 23.5s\n",
      "625:\tlearn: 0.0900387\ttotal: 39.2s\tremaining: 23.4s\n",
      "626:\tlearn: 0.0898955\ttotal: 39.3s\tremaining: 23.4s\n",
      "627:\tlearn: 0.0898406\ttotal: 39.4s\tremaining: 23.3s\n",
      "628:\tlearn: 0.0897542\ttotal: 39.4s\tremaining: 23.3s\n",
      "629:\tlearn: 0.0895760\ttotal: 39.5s\tremaining: 23.2s\n",
      "630:\tlearn: 0.0894619\ttotal: 39.6s\tremaining: 23.1s\n",
      "631:\tlearn: 0.0893475\ttotal: 39.6s\tremaining: 23.1s\n",
      "632:\tlearn: 0.0893138\ttotal: 39.7s\tremaining: 23s\n",
      "633:\tlearn: 0.0890779\ttotal: 39.7s\tremaining: 22.9s\n",
      "634:\tlearn: 0.0889135\ttotal: 39.8s\tremaining: 22.9s\n",
      "635:\tlearn: 0.0888579\ttotal: 39.9s\tremaining: 22.8s\n",
      "636:\tlearn: 0.0885233\ttotal: 39.9s\tremaining: 22.8s\n",
      "637:\tlearn: 0.0884414\ttotal: 40s\tremaining: 22.7s\n",
      "638:\tlearn: 0.0883634\ttotal: 40.1s\tremaining: 22.6s\n",
      "639:\tlearn: 0.0881847\ttotal: 40.1s\tremaining: 22.6s\n",
      "640:\tlearn: 0.0878280\ttotal: 40.2s\tremaining: 22.5s\n",
      "641:\tlearn: 0.0875502\ttotal: 40.3s\tremaining: 22.4s\n",
      "642:\tlearn: 0.0873188\ttotal: 40.3s\tremaining: 22.4s\n",
      "643:\tlearn: 0.0870902\ttotal: 40.4s\tremaining: 22.3s\n",
      "644:\tlearn: 0.0868988\ttotal: 40.4s\tremaining: 22.3s\n",
      "645:\tlearn: 0.0868412\ttotal: 40.5s\tremaining: 22.2s\n",
      "646:\tlearn: 0.0864756\ttotal: 40.6s\tremaining: 22.1s\n",
      "647:\tlearn: 0.0863104\ttotal: 40.6s\tremaining: 22.1s\n",
      "648:\tlearn: 0.0859167\ttotal: 40.7s\tremaining: 22s\n",
      "649:\tlearn: 0.0857436\ttotal: 40.7s\tremaining: 21.9s\n",
      "650:\tlearn: 0.0856376\ttotal: 40.8s\tremaining: 21.9s\n",
      "651:\tlearn: 0.0852339\ttotal: 40.9s\tremaining: 21.8s\n",
      "652:\tlearn: 0.0850542\ttotal: 40.9s\tremaining: 21.8s\n",
      "653:\tlearn: 0.0848313\ttotal: 41s\tremaining: 21.7s\n",
      "654:\tlearn: 0.0845633\ttotal: 41.1s\tremaining: 21.6s\n",
      "655:\tlearn: 0.0844160\ttotal: 41.1s\tremaining: 21.6s\n",
      "656:\tlearn: 0.0842740\ttotal: 41.2s\tremaining: 21.5s\n",
      "657:\tlearn: 0.0840673\ttotal: 41.2s\tremaining: 21.4s\n",
      "658:\tlearn: 0.0839746\ttotal: 41.3s\tremaining: 21.4s\n",
      "659:\tlearn: 0.0838956\ttotal: 41.4s\tremaining: 21.3s\n",
      "660:\tlearn: 0.0838118\ttotal: 41.4s\tremaining: 21.2s\n",
      "661:\tlearn: 0.0835934\ttotal: 41.5s\tremaining: 21.2s\n",
      "662:\tlearn: 0.0834508\ttotal: 41.6s\tremaining: 21.1s\n",
      "663:\tlearn: 0.0833573\ttotal: 41.6s\tremaining: 21.1s\n",
      "664:\tlearn: 0.0829842\ttotal: 41.7s\tremaining: 21s\n",
      "665:\tlearn: 0.0828283\ttotal: 41.7s\tremaining: 20.9s\n",
      "666:\tlearn: 0.0827623\ttotal: 41.8s\tremaining: 20.9s\n",
      "667:\tlearn: 0.0826368\ttotal: 41.9s\tremaining: 20.8s\n",
      "668:\tlearn: 0.0824863\ttotal: 41.9s\tremaining: 20.7s\n",
      "669:\tlearn: 0.0822196\ttotal: 42s\tremaining: 20.7s\n",
      "670:\tlearn: 0.0819441\ttotal: 42.1s\tremaining: 20.6s\n",
      "671:\tlearn: 0.0815564\ttotal: 42.1s\tremaining: 20.6s\n",
      "672:\tlearn: 0.0813793\ttotal: 42.2s\tremaining: 20.5s\n",
      "673:\tlearn: 0.0809678\ttotal: 42.2s\tremaining: 20.4s\n",
      "674:\tlearn: 0.0806773\ttotal: 42.3s\tremaining: 20.4s\n",
      "675:\tlearn: 0.0804586\ttotal: 42.4s\tremaining: 20.3s\n",
      "676:\tlearn: 0.0802286\ttotal: 42.4s\tremaining: 20.2s\n",
      "677:\tlearn: 0.0801570\ttotal: 42.5s\tremaining: 20.2s\n",
      "678:\tlearn: 0.0799320\ttotal: 42.5s\tremaining: 20.1s\n",
      "679:\tlearn: 0.0798277\ttotal: 42.6s\tremaining: 20s\n",
      "680:\tlearn: 0.0796935\ttotal: 42.7s\tremaining: 20s\n",
      "681:\tlearn: 0.0795158\ttotal: 42.7s\tremaining: 19.9s\n",
      "682:\tlearn: 0.0794085\ttotal: 42.8s\tremaining: 19.9s\n",
      "683:\tlearn: 0.0793181\ttotal: 42.9s\tremaining: 19.8s\n",
      "684:\tlearn: 0.0792441\ttotal: 42.9s\tremaining: 19.7s\n",
      "685:\tlearn: 0.0791403\ttotal: 43s\tremaining: 19.7s\n",
      "686:\tlearn: 0.0789725\ttotal: 43.1s\tremaining: 19.6s\n",
      "687:\tlearn: 0.0788727\ttotal: 43.1s\tremaining: 19.6s\n",
      "688:\tlearn: 0.0787930\ttotal: 43.2s\tremaining: 19.5s\n",
      "689:\tlearn: 0.0787538\ttotal: 43.2s\tremaining: 19.4s\n",
      "690:\tlearn: 0.0785718\ttotal: 43.3s\tremaining: 19.4s\n",
      "691:\tlearn: 0.0783583\ttotal: 43.4s\tremaining: 19.3s\n",
      "692:\tlearn: 0.0782720\ttotal: 43.4s\tremaining: 19.2s\n",
      "693:\tlearn: 0.0780157\ttotal: 43.5s\tremaining: 19.2s\n",
      "694:\tlearn: 0.0779226\ttotal: 43.5s\tremaining: 19.1s\n",
      "695:\tlearn: 0.0778143\ttotal: 43.6s\tremaining: 19s\n",
      "696:\tlearn: 0.0777734\ttotal: 43.7s\tremaining: 19s\n",
      "697:\tlearn: 0.0776399\ttotal: 43.7s\tremaining: 18.9s\n",
      "698:\tlearn: 0.0775707\ttotal: 43.8s\tremaining: 18.9s\n",
      "699:\tlearn: 0.0774727\ttotal: 43.9s\tremaining: 18.8s\n",
      "700:\tlearn: 0.0773122\ttotal: 43.9s\tremaining: 18.7s\n",
      "701:\tlearn: 0.0772405\ttotal: 44s\tremaining: 18.7s\n",
      "702:\tlearn: 0.0770344\ttotal: 44.1s\tremaining: 18.6s\n",
      "703:\tlearn: 0.0768681\ttotal: 44.2s\tremaining: 18.6s\n",
      "704:\tlearn: 0.0767846\ttotal: 44.2s\tremaining: 18.5s\n",
      "705:\tlearn: 0.0765228\ttotal: 44.3s\tremaining: 18.4s\n",
      "706:\tlearn: 0.0762939\ttotal: 44.3s\tremaining: 18.4s\n",
      "707:\tlearn: 0.0762434\ttotal: 44.4s\tremaining: 18.3s\n",
      "708:\tlearn: 0.0760665\ttotal: 44.5s\tremaining: 18.2s\n",
      "709:\tlearn: 0.0759225\ttotal: 44.5s\tremaining: 18.2s\n",
      "710:\tlearn: 0.0757318\ttotal: 44.6s\tremaining: 18.1s\n",
      "711:\tlearn: 0.0756082\ttotal: 44.7s\tremaining: 18.1s\n",
      "712:\tlearn: 0.0755500\ttotal: 44.7s\tremaining: 18s\n",
      "713:\tlearn: 0.0754235\ttotal: 44.8s\tremaining: 17.9s\n",
      "714:\tlearn: 0.0753459\ttotal: 44.8s\tremaining: 17.9s\n",
      "715:\tlearn: 0.0752997\ttotal: 44.9s\tremaining: 17.8s\n",
      "716:\tlearn: 0.0751315\ttotal: 45s\tremaining: 17.7s\n",
      "717:\tlearn: 0.0749648\ttotal: 45s\tremaining: 17.7s\n",
      "718:\tlearn: 0.0747212\ttotal: 45.1s\tremaining: 17.6s\n",
      "719:\tlearn: 0.0746803\ttotal: 45.2s\tremaining: 17.6s\n",
      "720:\tlearn: 0.0745228\ttotal: 45.2s\tremaining: 17.5s\n",
      "721:\tlearn: 0.0744420\ttotal: 45.3s\tremaining: 17.4s\n",
      "722:\tlearn: 0.0742482\ttotal: 45.3s\tremaining: 17.4s\n",
      "723:\tlearn: 0.0740775\ttotal: 45.4s\tremaining: 17.3s\n",
      "724:\tlearn: 0.0740057\ttotal: 45.5s\tremaining: 17.2s\n",
      "725:\tlearn: 0.0739170\ttotal: 45.5s\tremaining: 17.2s\n",
      "726:\tlearn: 0.0738639\ttotal: 45.6s\tremaining: 17.1s\n",
      "727:\tlearn: 0.0736635\ttotal: 45.6s\tremaining: 17.1s\n",
      "728:\tlearn: 0.0733442\ttotal: 45.7s\tremaining: 17s\n",
      "729:\tlearn: 0.0732360\ttotal: 45.8s\tremaining: 16.9s\n",
      "730:\tlearn: 0.0731764\ttotal: 45.8s\tremaining: 16.9s\n",
      "731:\tlearn: 0.0729332\ttotal: 45.9s\tremaining: 16.8s\n",
      "732:\tlearn: 0.0725709\ttotal: 46s\tremaining: 16.7s\n",
      "733:\tlearn: 0.0724757\ttotal: 46s\tremaining: 16.7s\n",
      "734:\tlearn: 0.0723351\ttotal: 46.1s\tremaining: 16.6s\n",
      "735:\tlearn: 0.0721402\ttotal: 46.1s\tremaining: 16.6s\n",
      "736:\tlearn: 0.0720981\ttotal: 46.2s\tremaining: 16.5s\n",
      "737:\tlearn: 0.0718470\ttotal: 46.3s\tremaining: 16.4s\n",
      "738:\tlearn: 0.0717563\ttotal: 46.3s\tremaining: 16.4s\n",
      "739:\tlearn: 0.0715431\ttotal: 46.4s\tremaining: 16.3s\n",
      "740:\tlearn: 0.0714013\ttotal: 46.4s\tremaining: 16.2s\n",
      "741:\tlearn: 0.0713648\ttotal: 46.5s\tremaining: 16.2s\n",
      "742:\tlearn: 0.0712346\ttotal: 46.6s\tremaining: 16.1s\n",
      "743:\tlearn: 0.0709424\ttotal: 46.6s\tremaining: 16s\n",
      "744:\tlearn: 0.0707756\ttotal: 46.7s\tremaining: 16s\n",
      "745:\tlearn: 0.0706386\ttotal: 46.8s\tremaining: 15.9s\n",
      "746:\tlearn: 0.0703567\ttotal: 46.8s\tremaining: 15.9s\n",
      "747:\tlearn: 0.0701750\ttotal: 46.9s\tremaining: 15.8s\n",
      "748:\tlearn: 0.0699734\ttotal: 46.9s\tremaining: 15.7s\n",
      "749:\tlearn: 0.0698925\ttotal: 47s\tremaining: 15.7s\n",
      "750:\tlearn: 0.0698105\ttotal: 47.1s\tremaining: 15.6s\n",
      "751:\tlearn: 0.0697734\ttotal: 47.1s\tremaining: 15.5s\n",
      "752:\tlearn: 0.0696679\ttotal: 47.2s\tremaining: 15.5s\n",
      "753:\tlearn: 0.0695688\ttotal: 47.3s\tremaining: 15.4s\n",
      "754:\tlearn: 0.0695072\ttotal: 47.3s\tremaining: 15.4s\n",
      "755:\tlearn: 0.0693574\ttotal: 47.4s\tremaining: 15.3s\n",
      "756:\tlearn: 0.0692088\ttotal: 47.4s\tremaining: 15.2s\n",
      "757:\tlearn: 0.0690492\ttotal: 47.5s\tremaining: 15.2s\n",
      "758:\tlearn: 0.0689791\ttotal: 47.6s\tremaining: 15.1s\n",
      "759:\tlearn: 0.0688954\ttotal: 47.6s\tremaining: 15s\n",
      "760:\tlearn: 0.0687440\ttotal: 47.7s\tremaining: 15s\n",
      "761:\tlearn: 0.0685659\ttotal: 47.8s\tremaining: 14.9s\n",
      "762:\tlearn: 0.0684405\ttotal: 47.8s\tremaining: 14.8s\n",
      "763:\tlearn: 0.0684157\ttotal: 47.9s\tremaining: 14.8s\n",
      "764:\tlearn: 0.0683118\ttotal: 47.9s\tremaining: 14.7s\n",
      "765:\tlearn: 0.0682123\ttotal: 48s\tremaining: 14.7s\n",
      "766:\tlearn: 0.0681599\ttotal: 48.1s\tremaining: 14.6s\n",
      "767:\tlearn: 0.0679967\ttotal: 48.1s\tremaining: 14.5s\n",
      "768:\tlearn: 0.0676726\ttotal: 48.2s\tremaining: 14.5s\n",
      "769:\tlearn: 0.0674390\ttotal: 48.3s\tremaining: 14.4s\n",
      "770:\tlearn: 0.0673522\ttotal: 48.3s\tremaining: 14.4s\n",
      "771:\tlearn: 0.0673115\ttotal: 48.4s\tremaining: 14.3s\n",
      "772:\tlearn: 0.0671658\ttotal: 48.5s\tremaining: 14.2s\n",
      "773:\tlearn: 0.0670664\ttotal: 48.5s\tremaining: 14.2s\n",
      "774:\tlearn: 0.0669858\ttotal: 48.6s\tremaining: 14.1s\n",
      "775:\tlearn: 0.0667424\ttotal: 48.6s\tremaining: 14s\n",
      "776:\tlearn: 0.0666261\ttotal: 48.7s\tremaining: 14s\n",
      "777:\tlearn: 0.0665583\ttotal: 48.8s\tremaining: 13.9s\n",
      "778:\tlearn: 0.0665110\ttotal: 48.9s\tremaining: 13.9s\n",
      "779:\tlearn: 0.0664717\ttotal: 48.9s\tremaining: 13.8s\n",
      "780:\tlearn: 0.0661713\ttotal: 49s\tremaining: 13.7s\n",
      "781:\tlearn: 0.0661221\ttotal: 49s\tremaining: 13.7s\n",
      "782:\tlearn: 0.0659967\ttotal: 49.1s\tremaining: 13.6s\n",
      "783:\tlearn: 0.0659027\ttotal: 49.2s\tremaining: 13.5s\n",
      "784:\tlearn: 0.0658305\ttotal: 49.2s\tremaining: 13.5s\n",
      "785:\tlearn: 0.0656036\ttotal: 49.3s\tremaining: 13.4s\n",
      "786:\tlearn: 0.0655495\ttotal: 49.4s\tremaining: 13.4s\n",
      "787:\tlearn: 0.0654684\ttotal: 49.4s\tremaining: 13.3s\n",
      "788:\tlearn: 0.0652659\ttotal: 49.5s\tremaining: 13.2s\n",
      "789:\tlearn: 0.0652162\ttotal: 49.6s\tremaining: 13.2s\n",
      "790:\tlearn: 0.0650057\ttotal: 49.6s\tremaining: 13.1s\n",
      "791:\tlearn: 0.0649240\ttotal: 49.7s\tremaining: 13s\n",
      "792:\tlearn: 0.0648403\ttotal: 49.7s\tremaining: 13s\n",
      "793:\tlearn: 0.0647193\ttotal: 49.8s\tremaining: 12.9s\n",
      "794:\tlearn: 0.0645093\ttotal: 49.9s\tremaining: 12.9s\n",
      "795:\tlearn: 0.0643656\ttotal: 49.9s\tremaining: 12.8s\n",
      "796:\tlearn: 0.0643194\ttotal: 50s\tremaining: 12.7s\n",
      "797:\tlearn: 0.0642162\ttotal: 50.1s\tremaining: 12.7s\n",
      "798:\tlearn: 0.0640044\ttotal: 50.1s\tremaining: 12.6s\n",
      "799:\tlearn: 0.0639367\ttotal: 50.2s\tremaining: 12.5s\n",
      "800:\tlearn: 0.0639075\ttotal: 50.3s\tremaining: 12.5s\n",
      "801:\tlearn: 0.0637610\ttotal: 50.3s\tremaining: 12.4s\n",
      "802:\tlearn: 0.0636678\ttotal: 50.4s\tremaining: 12.4s\n",
      "803:\tlearn: 0.0635209\ttotal: 50.4s\tremaining: 12.3s\n",
      "804:\tlearn: 0.0634857\ttotal: 50.5s\tremaining: 12.2s\n",
      "805:\tlearn: 0.0634367\ttotal: 50.6s\tremaining: 12.2s\n",
      "806:\tlearn: 0.0633180\ttotal: 50.6s\tremaining: 12.1s\n",
      "807:\tlearn: 0.0631921\ttotal: 50.7s\tremaining: 12s\n",
      "808:\tlearn: 0.0629870\ttotal: 50.8s\tremaining: 12s\n",
      "809:\tlearn: 0.0628822\ttotal: 50.8s\tremaining: 11.9s\n",
      "810:\tlearn: 0.0628273\ttotal: 50.9s\tremaining: 11.9s\n",
      "811:\tlearn: 0.0627531\ttotal: 50.9s\tremaining: 11.8s\n",
      "812:\tlearn: 0.0626524\ttotal: 51s\tremaining: 11.7s\n",
      "813:\tlearn: 0.0625444\ttotal: 51.1s\tremaining: 11.7s\n",
      "814:\tlearn: 0.0623722\ttotal: 51.1s\tremaining: 11.6s\n",
      "815:\tlearn: 0.0623376\ttotal: 51.2s\tremaining: 11.5s\n",
      "816:\tlearn: 0.0622953\ttotal: 51.2s\tremaining: 11.5s\n",
      "817:\tlearn: 0.0622396\ttotal: 51.3s\tremaining: 11.4s\n",
      "818:\tlearn: 0.0621609\ttotal: 51.4s\tremaining: 11.4s\n",
      "819:\tlearn: 0.0620153\ttotal: 51.4s\tremaining: 11.3s\n",
      "820:\tlearn: 0.0618825\ttotal: 51.5s\tremaining: 11.2s\n",
      "821:\tlearn: 0.0616313\ttotal: 51.6s\tremaining: 11.2s\n",
      "822:\tlearn: 0.0615715\ttotal: 51.6s\tremaining: 11.1s\n",
      "823:\tlearn: 0.0615213\ttotal: 51.7s\tremaining: 11s\n",
      "824:\tlearn: 0.0614516\ttotal: 51.7s\tremaining: 11s\n",
      "825:\tlearn: 0.0613817\ttotal: 51.8s\tremaining: 10.9s\n",
      "826:\tlearn: 0.0612948\ttotal: 51.9s\tremaining: 10.8s\n",
      "827:\tlearn: 0.0611289\ttotal: 51.9s\tremaining: 10.8s\n",
      "828:\tlearn: 0.0610515\ttotal: 52s\tremaining: 10.7s\n",
      "829:\tlearn: 0.0609453\ttotal: 52s\tremaining: 10.7s\n",
      "830:\tlearn: 0.0607281\ttotal: 52.1s\tremaining: 10.6s\n",
      "831:\tlearn: 0.0604925\ttotal: 52.2s\tremaining: 10.5s\n",
      "832:\tlearn: 0.0603767\ttotal: 52.2s\tremaining: 10.5s\n",
      "833:\tlearn: 0.0602424\ttotal: 52.3s\tremaining: 10.4s\n",
      "834:\tlearn: 0.0601137\ttotal: 52.4s\tremaining: 10.3s\n",
      "835:\tlearn: 0.0599882\ttotal: 52.4s\tremaining: 10.3s\n",
      "836:\tlearn: 0.0599498\ttotal: 52.5s\tremaining: 10.2s\n",
      "837:\tlearn: 0.0598443\ttotal: 52.5s\tremaining: 10.2s\n",
      "838:\tlearn: 0.0596941\ttotal: 52.6s\tremaining: 10.1s\n",
      "839:\tlearn: 0.0595785\ttotal: 52.7s\tremaining: 10s\n",
      "840:\tlearn: 0.0594162\ttotal: 52.7s\tremaining: 9.97s\n",
      "841:\tlearn: 0.0593291\ttotal: 52.8s\tremaining: 9.9s\n",
      "842:\tlearn: 0.0591584\ttotal: 52.8s\tremaining: 9.84s\n",
      "843:\tlearn: 0.0589924\ttotal: 52.9s\tremaining: 9.78s\n",
      "844:\tlearn: 0.0588069\ttotal: 53s\tremaining: 9.72s\n",
      "845:\tlearn: 0.0585916\ttotal: 53s\tremaining: 9.65s\n",
      "846:\tlearn: 0.0585127\ttotal: 53.1s\tremaining: 9.59s\n",
      "847:\tlearn: 0.0584274\ttotal: 53.2s\tremaining: 9.53s\n",
      "848:\tlearn: 0.0582550\ttotal: 53.2s\tremaining: 9.46s\n",
      "849:\tlearn: 0.0582050\ttotal: 53.3s\tremaining: 9.4s\n",
      "850:\tlearn: 0.0581686\ttotal: 53.3s\tremaining: 9.34s\n",
      "851:\tlearn: 0.0580807\ttotal: 53.4s\tremaining: 9.28s\n",
      "852:\tlearn: 0.0580263\ttotal: 53.5s\tremaining: 9.22s\n",
      "853:\tlearn: 0.0579826\ttotal: 53.6s\tremaining: 9.16s\n",
      "854:\tlearn: 0.0579212\ttotal: 53.6s\tremaining: 9.09s\n",
      "855:\tlearn: 0.0577947\ttotal: 53.7s\tremaining: 9.03s\n",
      "856:\tlearn: 0.0577568\ttotal: 53.8s\tremaining: 8.97s\n",
      "857:\tlearn: 0.0576738\ttotal: 53.8s\tremaining: 8.91s\n",
      "858:\tlearn: 0.0576030\ttotal: 53.9s\tremaining: 8.84s\n",
      "859:\tlearn: 0.0575293\ttotal: 53.9s\tremaining: 8.78s\n",
      "860:\tlearn: 0.0573444\ttotal: 54s\tremaining: 8.72s\n",
      "861:\tlearn: 0.0572273\ttotal: 54.1s\tremaining: 8.66s\n",
      "862:\tlearn: 0.0570872\ttotal: 54.1s\tremaining: 8.59s\n",
      "863:\tlearn: 0.0569688\ttotal: 54.2s\tremaining: 8.53s\n",
      "864:\tlearn: 0.0569230\ttotal: 54.2s\tremaining: 8.47s\n",
      "865:\tlearn: 0.0568264\ttotal: 54.3s\tremaining: 8.4s\n",
      "866:\tlearn: 0.0566997\ttotal: 54.4s\tremaining: 8.34s\n",
      "867:\tlearn: 0.0566741\ttotal: 54.4s\tremaining: 8.28s\n",
      "868:\tlearn: 0.0565220\ttotal: 54.5s\tremaining: 8.21s\n",
      "869:\tlearn: 0.0564494\ttotal: 54.6s\tremaining: 8.15s\n",
      "870:\tlearn: 0.0563568\ttotal: 54.6s\tremaining: 8.09s\n",
      "871:\tlearn: 0.0563078\ttotal: 54.7s\tremaining: 8.03s\n",
      "872:\tlearn: 0.0561628\ttotal: 54.8s\tremaining: 7.96s\n",
      "873:\tlearn: 0.0560204\ttotal: 54.8s\tremaining: 7.9s\n",
      "874:\tlearn: 0.0559825\ttotal: 54.9s\tremaining: 7.84s\n",
      "875:\tlearn: 0.0559617\ttotal: 54.9s\tremaining: 7.78s\n",
      "876:\tlearn: 0.0558550\ttotal: 55s\tremaining: 7.72s\n",
      "877:\tlearn: 0.0557869\ttotal: 55.1s\tremaining: 7.65s\n",
      "878:\tlearn: 0.0556999\ttotal: 55.2s\tremaining: 7.59s\n",
      "879:\tlearn: 0.0555682\ttotal: 55.2s\tremaining: 7.53s\n",
      "880:\tlearn: 0.0555263\ttotal: 55.3s\tremaining: 7.47s\n",
      "881:\tlearn: 0.0553420\ttotal: 55.3s\tremaining: 7.4s\n",
      "882:\tlearn: 0.0551730\ttotal: 55.4s\tremaining: 7.34s\n",
      "883:\tlearn: 0.0550938\ttotal: 55.5s\tremaining: 7.28s\n",
      "884:\tlearn: 0.0550182\ttotal: 55.5s\tremaining: 7.21s\n",
      "885:\tlearn: 0.0549368\ttotal: 55.6s\tremaining: 7.15s\n",
      "886:\tlearn: 0.0547792\ttotal: 55.7s\tremaining: 7.09s\n",
      "887:\tlearn: 0.0547118\ttotal: 55.7s\tremaining: 7.03s\n",
      "888:\tlearn: 0.0546511\ttotal: 55.8s\tremaining: 6.96s\n",
      "889:\tlearn: 0.0546387\ttotal: 55.8s\tremaining: 6.9s\n",
      "890:\tlearn: 0.0544956\ttotal: 55.9s\tremaining: 6.84s\n",
      "891:\tlearn: 0.0544530\ttotal: 56s\tremaining: 6.78s\n",
      "892:\tlearn: 0.0543801\ttotal: 56s\tremaining: 6.71s\n",
      "893:\tlearn: 0.0543291\ttotal: 56.1s\tremaining: 6.65s\n",
      "894:\tlearn: 0.0542100\ttotal: 56.1s\tremaining: 6.59s\n",
      "895:\tlearn: 0.0541474\ttotal: 56.2s\tremaining: 6.52s\n",
      "896:\tlearn: 0.0540911\ttotal: 56.3s\tremaining: 6.46s\n",
      "897:\tlearn: 0.0539764\ttotal: 56.3s\tremaining: 6.4s\n",
      "898:\tlearn: 0.0539409\ttotal: 56.4s\tremaining: 6.34s\n",
      "899:\tlearn: 0.0538846\ttotal: 56.5s\tremaining: 6.27s\n",
      "900:\tlearn: 0.0538423\ttotal: 56.5s\tremaining: 6.21s\n",
      "901:\tlearn: 0.0537483\ttotal: 56.6s\tremaining: 6.15s\n",
      "902:\tlearn: 0.0537203\ttotal: 56.6s\tremaining: 6.08s\n",
      "903:\tlearn: 0.0536556\ttotal: 56.7s\tremaining: 6.02s\n",
      "904:\tlearn: 0.0536252\ttotal: 56.8s\tremaining: 5.96s\n",
      "905:\tlearn: 0.0535045\ttotal: 56.8s\tremaining: 5.89s\n",
      "906:\tlearn: 0.0534433\ttotal: 56.9s\tremaining: 5.83s\n",
      "907:\tlearn: 0.0533749\ttotal: 56.9s\tremaining: 5.77s\n",
      "908:\tlearn: 0.0532122\ttotal: 57s\tremaining: 5.71s\n",
      "909:\tlearn: 0.0530114\ttotal: 57.1s\tremaining: 5.64s\n",
      "910:\tlearn: 0.0529546\ttotal: 57.1s\tremaining: 5.58s\n",
      "911:\tlearn: 0.0528434\ttotal: 57.2s\tremaining: 5.52s\n",
      "912:\tlearn: 0.0526449\ttotal: 57.2s\tremaining: 5.46s\n",
      "913:\tlearn: 0.0525834\ttotal: 57.3s\tremaining: 5.39s\n",
      "914:\tlearn: 0.0524477\ttotal: 57.4s\tremaining: 5.33s\n",
      "915:\tlearn: 0.0523347\ttotal: 57.4s\tremaining: 5.27s\n",
      "916:\tlearn: 0.0522887\ttotal: 57.5s\tremaining: 5.2s\n",
      "917:\tlearn: 0.0521789\ttotal: 57.6s\tremaining: 5.14s\n",
      "918:\tlearn: 0.0521367\ttotal: 57.6s\tremaining: 5.08s\n",
      "919:\tlearn: 0.0520612\ttotal: 57.7s\tremaining: 5.02s\n",
      "920:\tlearn: 0.0519239\ttotal: 57.7s\tremaining: 4.95s\n",
      "921:\tlearn: 0.0518474\ttotal: 57.8s\tremaining: 4.89s\n",
      "922:\tlearn: 0.0518300\ttotal: 57.9s\tremaining: 4.83s\n",
      "923:\tlearn: 0.0518080\ttotal: 57.9s\tremaining: 4.77s\n",
      "924:\tlearn: 0.0516153\ttotal: 58s\tremaining: 4.7s\n",
      "925:\tlearn: 0.0514852\ttotal: 58.1s\tremaining: 4.64s\n",
      "926:\tlearn: 0.0514623\ttotal: 58.1s\tremaining: 4.58s\n",
      "927:\tlearn: 0.0514161\ttotal: 58.2s\tremaining: 4.51s\n",
      "928:\tlearn: 0.0513660\ttotal: 58.3s\tremaining: 4.45s\n",
      "929:\tlearn: 0.0512616\ttotal: 58.3s\tremaining: 4.39s\n",
      "930:\tlearn: 0.0511941\ttotal: 58.4s\tremaining: 4.33s\n",
      "931:\tlearn: 0.0511297\ttotal: 58.5s\tremaining: 4.27s\n",
      "932:\tlearn: 0.0509653\ttotal: 58.6s\tremaining: 4.21s\n",
      "933:\tlearn: 0.0508840\ttotal: 58.6s\tremaining: 4.14s\n",
      "934:\tlearn: 0.0508169\ttotal: 58.7s\tremaining: 4.08s\n",
      "935:\tlearn: 0.0507425\ttotal: 58.8s\tremaining: 4.02s\n",
      "936:\tlearn: 0.0506948\ttotal: 58.8s\tremaining: 3.96s\n",
      "937:\tlearn: 0.0506241\ttotal: 58.9s\tremaining: 3.89s\n",
      "938:\tlearn: 0.0504965\ttotal: 59s\tremaining: 3.83s\n",
      "939:\tlearn: 0.0503693\ttotal: 59s\tremaining: 3.77s\n",
      "940:\tlearn: 0.0502334\ttotal: 59.1s\tremaining: 3.71s\n",
      "941:\tlearn: 0.0501375\ttotal: 59.2s\tremaining: 3.64s\n",
      "942:\tlearn: 0.0501020\ttotal: 59.2s\tremaining: 3.58s\n",
      "943:\tlearn: 0.0500203\ttotal: 59.3s\tremaining: 3.52s\n",
      "944:\tlearn: 0.0499053\ttotal: 59.3s\tremaining: 3.45s\n",
      "945:\tlearn: 0.0498611\ttotal: 59.4s\tremaining: 3.39s\n",
      "946:\tlearn: 0.0496977\ttotal: 59.5s\tremaining: 3.33s\n",
      "947:\tlearn: 0.0495785\ttotal: 59.5s\tremaining: 3.27s\n",
      "948:\tlearn: 0.0495029\ttotal: 59.6s\tremaining: 3.2s\n",
      "949:\tlearn: 0.0493775\ttotal: 59.7s\tremaining: 3.14s\n",
      "950:\tlearn: 0.0493346\ttotal: 59.7s\tremaining: 3.08s\n",
      "951:\tlearn: 0.0492951\ttotal: 59.8s\tremaining: 3.01s\n",
      "952:\tlearn: 0.0492453\ttotal: 59.8s\tremaining: 2.95s\n",
      "953:\tlearn: 0.0491466\ttotal: 59.9s\tremaining: 2.89s\n",
      "954:\tlearn: 0.0491128\ttotal: 60s\tremaining: 2.83s\n",
      "955:\tlearn: 0.0489821\ttotal: 1m\tremaining: 2.76s\n",
      "956:\tlearn: 0.0489453\ttotal: 1m\tremaining: 2.7s\n",
      "957:\tlearn: 0.0488880\ttotal: 1m\tremaining: 2.64s\n",
      "958:\tlearn: 0.0488471\ttotal: 1m\tremaining: 2.57s\n",
      "959:\tlearn: 0.0487673\ttotal: 1m\tremaining: 2.51s\n",
      "960:\tlearn: 0.0486702\ttotal: 1m\tremaining: 2.45s\n",
      "961:\tlearn: 0.0485740\ttotal: 1m\tremaining: 2.39s\n",
      "962:\tlearn: 0.0484871\ttotal: 1m\tremaining: 2.32s\n",
      "963:\tlearn: 0.0484421\ttotal: 1m\tremaining: 2.26s\n",
      "964:\tlearn: 0.0483739\ttotal: 1m\tremaining: 2.2s\n",
      "965:\tlearn: 0.0482708\ttotal: 1m\tremaining: 2.13s\n",
      "966:\tlearn: 0.0482318\ttotal: 1m\tremaining: 2.07s\n",
      "967:\tlearn: 0.0481347\ttotal: 1m\tremaining: 2.01s\n",
      "968:\tlearn: 0.0480420\ttotal: 1m\tremaining: 1.95s\n",
      "969:\tlearn: 0.0479417\ttotal: 1m\tremaining: 1.88s\n",
      "970:\tlearn: 0.0478526\ttotal: 1m\tremaining: 1.82s\n",
      "971:\tlearn: 0.0477552\ttotal: 1m 1s\tremaining: 1.76s\n",
      "972:\tlearn: 0.0477035\ttotal: 1m 1s\tremaining: 1.7s\n",
      "973:\tlearn: 0.0476843\ttotal: 1m 1s\tremaining: 1.63s\n",
      "974:\tlearn: 0.0476492\ttotal: 1m 1s\tremaining: 1.57s\n",
      "975:\tlearn: 0.0476060\ttotal: 1m 1s\tremaining: 1.51s\n",
      "976:\tlearn: 0.0475650\ttotal: 1m 1s\tremaining: 1.44s\n",
      "977:\tlearn: 0.0475087\ttotal: 1m 1s\tremaining: 1.38s\n",
      "978:\tlearn: 0.0473923\ttotal: 1m 1s\tremaining: 1.32s\n",
      "979:\tlearn: 0.0472961\ttotal: 1m 1s\tremaining: 1.25s\n",
      "980:\tlearn: 0.0472396\ttotal: 1m 1s\tremaining: 1.19s\n",
      "981:\tlearn: 0.0471864\ttotal: 1m 1s\tremaining: 1.13s\n",
      "982:\tlearn: 0.0470309\ttotal: 1m 1s\tremaining: 1.07s\n",
      "983:\tlearn: 0.0469614\ttotal: 1m 1s\tremaining: 1s\n",
      "984:\tlearn: 0.0468563\ttotal: 1m 1s\tremaining: 942ms\n",
      "985:\tlearn: 0.0467955\ttotal: 1m 1s\tremaining: 879ms\n",
      "986:\tlearn: 0.0467025\ttotal: 1m 1s\tremaining: 816ms\n",
      "987:\tlearn: 0.0466306\ttotal: 1m 2s\tremaining: 753ms\n",
      "988:\tlearn: 0.0465747\ttotal: 1m 2s\tremaining: 691ms\n",
      "989:\tlearn: 0.0464707\ttotal: 1m 2s\tremaining: 628ms\n",
      "990:\tlearn: 0.0464303\ttotal: 1m 2s\tremaining: 565ms\n",
      "991:\tlearn: 0.0463474\ttotal: 1m 2s\tremaining: 502ms\n",
      "992:\tlearn: 0.0462100\ttotal: 1m 2s\tremaining: 440ms\n",
      "993:\tlearn: 0.0461201\ttotal: 1m 2s\tremaining: 377ms\n",
      "994:\tlearn: 0.0460819\ttotal: 1m 2s\tremaining: 314ms\n",
      "995:\tlearn: 0.0460048\ttotal: 1m 2s\tremaining: 251ms\n",
      "996:\tlearn: 0.0459558\ttotal: 1m 2s\tremaining: 188ms\n",
      "997:\tlearn: 0.0459096\ttotal: 1m 2s\tremaining: 126ms\n",
      "998:\tlearn: 0.0457917\ttotal: 1m 2s\tremaining: 62.8ms\n",
      "999:\tlearn: 0.0457731\ttotal: 1m 2s\tremaining: 0us\n",
      "Accuracy (CatBoost Baseline with SMOTE): 0.9876093294460642\n",
      "Classification Report (CatBoost Baseline with SMOTE):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0      0.961     0.987     0.974        75\n",
      "           1      1.000     0.983     0.992        60\n",
      "           2      0.978     0.978     0.978       182\n",
      "           3      1.000     0.973     0.986        37\n",
      "           4      0.991     0.986     0.988       212\n",
      "           5      0.975     1.000     0.987        77\n",
      "           6      0.988     0.992     0.990       248\n",
      "           7      1.000     1.000     1.000        41\n",
      "           8      0.983     0.983     0.983        58\n",
      "           9      1.000     0.976     0.988       167\n",
      "          10      1.000     1.000     1.000        43\n",
      "          11      0.920     0.821     0.868        28\n",
      "          12      1.000     1.000     1.000        66\n",
      "          13      1.000     1.000     1.000       223\n",
      "          14      0.973     0.964     0.969       112\n",
      "          15      0.990     0.995     0.992       194\n",
      "          16      0.983     0.989     0.986       178\n",
      "          17      1.000     0.962     0.980        26\n",
      "          18      0.971     1.000     0.986       102\n",
      "          19      1.000     0.959     0.979        49\n",
      "          20      0.988     1.000     0.994       410\n",
      "          21      0.994     0.987     0.990       156\n",
      "\n",
      "    accuracy                          0.988      2744\n",
      "   macro avg      0.986     0.979     0.982      2744\n",
      "weighted avg      0.988     0.988     0.988      2744\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')  # Ignore warnings for simplicity\n",
    "\n",
    "# Assuming X_train_resampled_smote, y_train_resampled_smote, X_test, y_test are defined\n",
    "\n",
    "# Initialize the CatBoost classifier with default parameters\n",
    "catboost_classifier = CatBoostClassifier(random_state=42)\n",
    "\n",
    "\n",
    "# Fit the CatBoost classifier\n",
    "catboost_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_catboost = catboost_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_catboost = accuracy_score(y_test, y_pred_catboost)\n",
    "classification_report_catboost = classification_report(y_test, y_pred_catboost, digits=3)\n",
    "\n",
    "# Print results\n",
    "print(f\"Accuracy (CatBoost Baseline with SMOTE): {accuracy_catboost}\")\n",
    "print(\"Classification Report (CatBoost Baseline with SMOTE):\\n\", classification_report_catboost)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002807 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1486\n",
      "[LightGBM] [Info] Number of data points in the train set: 40722, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score -3.091042\n",
      "[LightGBM] [Info] Start training from score -3.091042\n",
      "[LightGBM] [Info] Start training from score -3.091042\n",
      "[LightGBM] [Info] Start training from score -3.091042\n",
      "[LightGBM] [Info] Start training from score -3.091042\n",
      "[LightGBM] [Info] Start training from score -3.091042\n",
      "[LightGBM] [Info] Start training from score -3.091042\n",
      "[LightGBM] [Info] Start training from score -3.091042\n",
      "[LightGBM] [Info] Start training from score -3.091042\n",
      "[LightGBM] [Info] Start training from score -3.091042\n",
      "[LightGBM] [Info] Start training from score -3.091042\n",
      "[LightGBM] [Info] Start training from score -3.091042\n",
      "[LightGBM] [Info] Start training from score -3.091042\n",
      "[LightGBM] [Info] Start training from score -3.091042\n",
      "[LightGBM] [Info] Start training from score -3.091042\n",
      "[LightGBM] [Info] Start training from score -3.091042\n",
      "[LightGBM] [Info] Start training from score -3.091042\n",
      "[LightGBM] [Info] Start training from score -3.091042\n",
      "[LightGBM] [Info] Start training from score -3.091042\n",
      "[LightGBM] [Info] Start training from score -3.091042\n",
      "[LightGBM] [Info] Start training from score -3.091042\n",
      "[LightGBM] [Info] Start training from score -3.091042\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Best Parameters (LGBM with SMOTE): {'max_depth': -1, 'n_estimators': 200}\n",
      "Accuracy (LGBM with SMOTE): 0.9650145772594753\n",
      "Classification Report (LGBM with SMOTE):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0      0.923     0.960     0.941        75\n",
      "           1      0.933     0.933     0.933        60\n",
      "           2      0.972     0.956     0.964       182\n",
      "           3      1.000     0.973     0.986        37\n",
      "           4      0.954     0.976     0.965       212\n",
      "           5      0.893     0.974     0.932        77\n",
      "           6      0.976     0.968     0.972       248\n",
      "           7      0.976     1.000     0.988        41\n",
      "           8      0.962     0.879     0.919        58\n",
      "           9      0.958     0.946     0.952       167\n",
      "          10      1.000     0.977     0.988        43\n",
      "          11      0.826     0.679     0.745        28\n",
      "          12      1.000     1.000     1.000        66\n",
      "          13      0.996     1.000     0.998       223\n",
      "          14      0.935     0.902     0.918       112\n",
      "          15      0.989     0.954     0.971       194\n",
      "          16      0.925     0.972     0.948       178\n",
      "          17      1.000     0.846     0.917        26\n",
      "          18      0.908     0.971     0.938       102\n",
      "          19      1.000     0.939     0.968        49\n",
      "          20      0.995     0.995     0.995       410\n",
      "          21      0.963     0.987     0.975       156\n",
      "\n",
      "    accuracy                          0.965      2744\n",
      "   macro avg      0.958     0.945     0.951      2744\n",
      "weighted avg      0.965     0.965     0.965      2744\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')  # Ignore warnings for simplicity\n",
    "\n",
    "# Define the parameter grid for LGBM\n",
    "param_grid = {\n",
    "    'max_depth': [-1, 2, 3, 4, 5],\n",
    "    'n_estimators': [50, 100, 150, 200],\n",
    "}\n",
    "\n",
    "# Initialize the LGBM classifier\n",
    "lgbm_classifier = LGBMClassifier(random_state=42)\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=lgbm_classifier,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,  # 5-fold cross-validation\n",
    "    verbose=2,\n",
    "    n_jobs=-1  # Use all available cores\n",
    ")\n",
    "\n",
    "# Assuming X_train_resampled_smote, y_train_resampled_smote are defined\n",
    "# Fit GridSearchCV on SMOTE resampled data\n",
    "grid_search.fit(X_train_resampled_smote, y_train_resampled_smote)\n",
    "\n",
    "# Get the best model\n",
    "best_lgbm_classifier = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on the test set using the best model\n",
    "y_pred_best_lgbm = best_lgbm_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the best model\n",
    "accuracy_best_lgbm = accuracy_score(y_test, y_pred_best_lgbm)\n",
    "classification_report_result_best_lgbm = classification_report(y_test, y_pred_best_lgbm, digits=3)\n",
    "\n",
    "# Print results\n",
    "print(f\"Best Parameters (LGBM with SMOTE): {grid_search.best_params_}\")\n",
    "print(f\"Accuracy (LGBM with SMOTE): {accuracy_best_lgbm}\")\n",
    "print(\"Classification Report (LGBM with SMOTE):\\n\", classification_report_result_best_lgbm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006120 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1485\n",
      "[LightGBM] [Info] Number of data points in the train set: 40722, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score -3.091042\n",
      "[LightGBM] [Info] Start training from score -3.091042\n",
      "[LightGBM] [Info] Start training from score -3.091042\n",
      "[LightGBM] [Info] Start training from score -3.091042\n",
      "[LightGBM] [Info] Start training from score -3.091042\n",
      "[LightGBM] [Info] Start training from score -3.091042\n",
      "[LightGBM] [Info] Start training from score -3.091042\n",
      "[LightGBM] [Info] Start training from score -3.091042\n",
      "[LightGBM] [Info] Start training from score -3.091042\n",
      "[LightGBM] [Info] Start training from score -3.091042\n",
      "[LightGBM] [Info] Start training from score -3.091042\n",
      "[LightGBM] [Info] Start training from score -3.091042\n",
      "[LightGBM] [Info] Start training from score -3.091042\n",
      "[LightGBM] [Info] Start training from score -3.091042\n",
      "[LightGBM] [Info] Start training from score -3.091042\n",
      "[LightGBM] [Info] Start training from score -3.091042\n",
      "[LightGBM] [Info] Start training from score -3.091042\n",
      "[LightGBM] [Info] Start training from score -3.091042\n",
      "[LightGBM] [Info] Start training from score -3.091042\n",
      "[LightGBM] [Info] Start training from score -3.091042\n",
      "[LightGBM] [Info] Start training from score -3.091042\n",
      "[LightGBM] [Info] Start training from score -3.091042\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Best Parameters (LGBM with SMOTE): {'max_depth': -1, 'n_estimators': 200}\n",
      "Accuracy (LGBM with SMOTE): 0.9686588921282799\n",
      "Classification Report (LGBM with SMOTE):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0      0.935     0.960     0.947        75\n",
      "           1      0.948     0.917     0.932        60\n",
      "           2      0.962     0.962     0.962       182\n",
      "           3      1.000     0.973     0.986        37\n",
      "           4      0.954     0.981     0.967       212\n",
      "           5      0.926     0.974     0.949        77\n",
      "           6      0.976     0.968     0.972       248\n",
      "           7      1.000     0.976     0.988        41\n",
      "           8      0.947     0.931     0.939        58\n",
      "           9      0.964     0.958     0.961       167\n",
      "          10      1.000     1.000     1.000        43\n",
      "          11      0.955     0.750     0.840        28\n",
      "          12      1.000     1.000     1.000        66\n",
      "          13      0.995     0.987     0.991       223\n",
      "          14      0.927     0.911     0.919       112\n",
      "          15      0.984     0.974     0.979       194\n",
      "          16      0.931     0.983     0.956       178\n",
      "          17      0.955     0.808     0.875        26\n",
      "          18      0.934     0.971     0.952       102\n",
      "          19      1.000     0.939     0.968        49\n",
      "          20      0.998     0.993     0.995       410\n",
      "          21      0.969     0.987     0.978       156\n",
      "\n",
      "    accuracy                          0.969      2744\n",
      "   macro avg      0.966     0.950     0.957      2744\n",
      "weighted avg      0.969     0.969     0.968      2744\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')  # Ignore warnings for simplicity\n",
    "\n",
    "# Define the parameter grid for LGBM\n",
    "param_grid = {\n",
    "    'max_depth': [-1, 2, 3, 4, 5],\n",
    "    'n_estimators': [50, 100, 150, 200],\n",
    "}\n",
    "\n",
    "# Initialize the LGBM classifier\n",
    "lgbm_classifier = LGBMClassifier(random_state=42)\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=lgbm_classifier,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,  # 5-fold cross-validation\n",
    "    verbose=2,\n",
    "    n_jobs=-1  # Use all available cores\n",
    ")\n",
    "\n",
    "# Assuming X_train_resampled_smote, y_train_resampled_smote are defined\n",
    "# Fit GridSearchCV on SMOTE resampled data\n",
    "grid_search.fit(X_train_resampled_borderline, y_train_resampled_borderline)\n",
    "\n",
    "# Get the best model\n",
    "best_lgbm_classifier = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on the test set using the best model\n",
    "y_pred_best_lgbm = best_lgbm_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the best model\n",
    "accuracy_best_lgbm = accuracy_score(y_test, y_pred_best_lgbm)\n",
    "classification_report_result_best_lgbm = classification_report(y_test, y_pred_best_lgbm, digits=3)\n",
    "\n",
    "# Print results\n",
    "print(f\"Best Parameters (LGBM with SMOTE): {grid_search.best_params_}\")\n",
    "print(f\"Accuracy (LGBM with SMOTE): {accuracy_best_lgbm}\")\n",
    "print(\"Classification Report (LGBM with SMOTE):\\n\", classification_report_result_best_lgbm)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
