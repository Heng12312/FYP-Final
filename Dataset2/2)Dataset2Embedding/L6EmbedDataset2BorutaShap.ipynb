{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np # linear algebra\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Replace 'path_to_dataset' with the actual path to your dataset file\n",
    "df = pd.read_csv('embedding_FirstStructureL6.csv')\n",
    "X_final= df\n",
    "\n",
    "df2 = pd.read_excel('Dataset2neww.xlsx')\n",
    "y = df2['Course']\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "\n",
    "# Initialize LabelEncoder for the target variable y\n",
    "label_encoder_y = LabelEncoder()\n",
    "y_encoded = label_encoder_y.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_final, y_encoded, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled_smote, y_train_resampled_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "borderline_smote = BorderlineSMOTE(random_state=42)\n",
    "X_train_resampled_borderline, y_train_resampled_borderline = borderline_smote.fit_resample(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BorutaShap SMOTE + Bordeline SMOTE\n",
    "focus on Bordeline SMOTE only also can"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\python\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\python\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_depth': None, 'n_estimators': 200}\n",
      "Accuracy (Best Random Forest with Borderline SMOTE): 0.32655367231638416\n",
      "Classification Report (Best Random Forest with Borderline SMOTE):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0      0.000     0.000     0.000         5\n",
      "           1      0.417     0.882     0.566        34\n",
      "           2      0.364     0.500     0.421        32\n",
      "           3      0.261     0.460     0.333        50\n",
      "           4      0.178     0.205     0.190        39\n",
      "           5      0.229     0.118     0.155        68\n",
      "           6      0.273     0.182     0.218        33\n",
      "           7      0.150     0.077     0.102        39\n",
      "           8      0.211     0.188     0.198        64\n",
      "           9      0.250     0.267     0.258        75\n",
      "          10      0.222     0.189     0.204        53\n",
      "          11      0.515     0.540     0.527       163\n",
      "          12      0.200     0.087     0.121        23\n",
      "          13      0.108     0.100     0.104        40\n",
      "          14      0.302     0.205     0.244        78\n",
      "          15      0.207     0.146     0.171        41\n",
      "          16      0.481     0.771     0.592        48\n",
      "\n",
      "    accuracy                          0.327       885\n",
      "   macro avg      0.257     0.289     0.259       885\n",
      "weighted avg      0.303     0.327     0.304       885\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Initialize Borderline SMOTE\n",
    "\n",
    "# Define the parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'max_depth': [2, 3, 4, 5, None],\n",
    "    'n_estimators': [50, 100, 150, 200],\n",
    "}\n",
    "\n",
    "# Initialize the Random Forest classifier\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=rf_classifier,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,  # 5-fold cross-validation\n",
    "    verbose=2,\n",
    "    n_jobs=-1  # Use all available cores\n",
    ")\n",
    "\n",
    "# Fit GridSearchCV with resampled data\n",
    "grid_search.fit(X_train_resampled_borderline, y_train_resampled_borderline)\n",
    "\n",
    "# Get the best model\n",
    "best_rf_classifier = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on the test set using the best model\n",
    "y_pred_best_rf = best_rf_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the best model\n",
    "accuracy_best_rf = accuracy_score(y_test, y_pred_best_rf)\n",
    "classification_report_result_best_rf = classification_report(y_test, y_pred_best_rf, digits=3)\n",
    "\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "print(f\"Accuracy (Best Random Forest with Borderline SMOTE): {accuracy_best_rf}\")\n",
    "print(\"Classification Report (Best Random Forest with Borderline SMOTE):\\n\", classification_report_result_best_rf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['best_rf.joblib']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the model to a file\n",
    "joblib_file = \"best_rf.joblib\"\n",
    "joblib.dump(best_rf_classifier, joblib_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gaussian NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python\\Lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'var_smoothing': 1e-09}\n",
      "Accuracy (Best GaussianNB with SMOTE): 0.20225988700564973\n",
      "Classification Report (Best GaussianNB with SMOTE):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0      0.143     0.400     0.211         5\n",
      "           1      0.333     0.706     0.453        34\n",
      "           2      0.318     0.438     0.368        32\n",
      "           3      0.248     0.520     0.335        50\n",
      "           4      0.060     0.205     0.092        39\n",
      "           5      0.067     0.015     0.024        68\n",
      "           6      0.333     0.061     0.103        33\n",
      "           7      0.167     0.128     0.145        39\n",
      "           8      0.095     0.109     0.101        64\n",
      "           9      0.139     0.067     0.090        75\n",
      "          10      0.045     0.019     0.027        53\n",
      "          11      0.579     0.202     0.300       163\n",
      "          12      0.000     0.000     0.000        23\n",
      "          13      0.000     0.000     0.000        40\n",
      "          14      0.268     0.141     0.185        78\n",
      "          15      0.075     0.268     0.117        41\n",
      "          16      0.403     0.604     0.483        48\n",
      "\n",
      "    accuracy                          0.202       885\n",
      "   macro avg      0.192     0.228     0.179       885\n",
      "weighted avg      0.244     0.202     0.187       885\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\python\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\python\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'var_smoothing': [1e-9, 1.778e-7, 3.162e-5, 5.6e-3, 1]\n",
    "}\n",
    "\n",
    "# Initialize the GaussianNB classifier\n",
    "gnb_classifier = GaussianNB()\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=gnb_classifier,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,  # 5-fold cross-validation\n",
    "    verbose=2,\n",
    "    n_jobs=-1  # Use all available cores\n",
    ")\n",
    "\n",
    "# Fit GridSearchCV\n",
    "grid_search.fit(X_train_resampled_borderline, y_train_resampled_borderline)\n",
    "\n",
    "# Get the best model\n",
    "best_gnb_classifier = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on the test set using the best model\n",
    "y_pred_best_gnb = best_gnb_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the best model\n",
    "accuracy_best_gnb = accuracy_score(y_test, y_pred_best_gnb)\n",
    "classification_report_result_best_gnb = classification_report(y_test, y_pred_best_gnb, digits=3)\n",
    "\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "print(f\"Accuracy (Best GaussianNB with SMOTE): {accuracy_best_gnb}\")\n",
    "print(\"Classification Report (Best GaussianNB with SMOTE):\\n\", classification_report_result_best_gnb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['best_gnb.joblib']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model to a file\n",
    "joblib_file = \"best_gnb.joblib\"\n",
    "joblib.dump(best_gnb_classifier, joblib_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Best Parameters: {'max_depth': None}\n",
      "Accuracy (Best Decision Tree with SMOTE): 0.2\n",
      "Classification Report (Best Decision Tree with SMOTE):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0      0.333     0.200     0.250         5\n",
      "           1      0.378     0.500     0.430        34\n",
      "           2      0.282     0.344     0.310        32\n",
      "           3      0.386     0.340     0.362        50\n",
      "           4      0.104     0.128     0.115        39\n",
      "           5      0.147     0.147     0.147        68\n",
      "           6      0.075     0.091     0.082        33\n",
      "           7      0.149     0.179     0.163        39\n",
      "           8      0.127     0.156     0.140        64\n",
      "           9      0.167     0.133     0.148        75\n",
      "          10      0.039     0.038     0.038        53\n",
      "          11      0.400     0.294     0.339       163\n",
      "          12      0.062     0.087     0.073        23\n",
      "          13      0.030     0.050     0.037        40\n",
      "          14      0.178     0.103     0.130        78\n",
      "          15      0.045     0.049     0.047        41\n",
      "          16      0.415     0.458     0.436        48\n",
      "\n",
      "    accuracy                          0.200       885\n",
      "   macro avg      0.195     0.194     0.191       885\n",
      "weighted avg      0.216     0.200     0.204       885\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'max_depth': [2, 3, 4, 5, None]\n",
    "}\n",
    "\n",
    "# Initialize the Decision Tree classifier\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=dt_classifier,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,  # 5-fold cross-validation\n",
    "    verbose=2,\n",
    "    n_jobs=-1  # Use all available cores\n",
    ")\n",
    "\n",
    "# Fit GridSearchCV\n",
    "grid_search.fit(X_train_resampled_borderline, y_train_resampled_borderline)\n",
    "\n",
    "# Get the best model\n",
    "best_dt_classifier = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on the test set using the best model\n",
    "y_pred_best_dt = best_dt_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the best model\n",
    "accuracy_best_dt = accuracy_score(y_test, y_pred_best_dt)\n",
    "classification_report_result_best_dt = classification_report(y_test, y_pred_best_dt, digits=3)\n",
    "\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "print(f\"Accuracy (Best Decision Tree with SMOTE): {accuracy_best_dt}\")\n",
    "print(\"Classification Report (Best Decision Tree with SMOTE):\\n\", classification_report_result_best_dt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['best_dt.joblib']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model to a file\n",
    "joblib_file = \"best_dt.joblib\"\n",
    "joblib.dump(best_dt_classifier, joblib_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Best Parameters: {'n_neighbors': 1}\n",
      "Accuracy (Best KNN with Borderline SMOTE): 0.25875706214689265\n",
      "Classification Report (Best KNN with Borderline SMOTE):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0      0.000     0.000     0.000         5\n",
      "           1      0.571     0.824     0.675        34\n",
      "           2      0.361     0.406     0.382        32\n",
      "           3      0.314     0.320     0.317        50\n",
      "           4      0.149     0.179     0.163        39\n",
      "           5      0.185     0.176     0.180        68\n",
      "           6      0.100     0.091     0.095        33\n",
      "           7      0.125     0.128     0.127        39\n",
      "           8      0.075     0.078     0.076        64\n",
      "           9      0.178     0.173     0.176        75\n",
      "          10      0.161     0.189     0.174        53\n",
      "          11      0.482     0.405     0.440       163\n",
      "          12      0.087     0.087     0.087        23\n",
      "          13      0.094     0.125     0.108        40\n",
      "          14      0.224     0.167     0.191        78\n",
      "          15      0.149     0.171     0.159        41\n",
      "          16      0.522     0.500     0.511        48\n",
      "\n",
      "    accuracy                          0.259       885\n",
      "   macro avg      0.222     0.236     0.227       885\n",
      "weighted avg      0.263     0.259     0.259       885\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assume X_final and y_encoded are your features and target after preprocessing\n",
    "\n",
    "\n",
    "# Apply StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Apply Borderline SMOTE to the training data only\n",
    "smote = BorderlineSMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "# Define the parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'n_neighbors': [1, 2, 3, 4, 5]\n",
    "}\n",
    "\n",
    "# Initialize the KNN classifier\n",
    "knn_classifier = KNeighborsClassifier()\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=knn_classifier,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,  # 5-fold cross-validation\n",
    "    verbose=2,\n",
    "    n_jobs=-1  # Use all available cores\n",
    ")\n",
    "\n",
    "# Fit GridSearchCV with resampled data\n",
    "grid_search.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Get the best model\n",
    "best_knn_classifier = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on the test set using the best model\n",
    "y_pred_best_knn = best_knn_classifier.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the best model\n",
    "accuracy_best_knn = accuracy_score(y_test, y_pred_best_knn)\n",
    "classification_report_result_best_knn = classification_report(y_test, y_pred_best_knn, digits=3)\n",
    "\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "print(f\"Accuracy (Best KNN with Borderline SMOTE): {accuracy_best_knn}\")\n",
    "print(\"Classification Report (Best KNN with Borderline SMOTE):\\n\", classification_report_result_best_knn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['best_knn.joblib']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model to a file\n",
    "joblib_file = \"best_knn.joblib\"\n",
    "joblib.dump(best_knn_classifier, joblib_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\python\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\python\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters (SVM with BorderlineSMOTE): {'C': 10, 'gamma': 0.01}\n",
      "Accuracy (SVM with BorderlineSMOTE): 0.3231638418079096\n",
      "Classification Report (SVM with BorderlineSMOTE):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0      0.000     0.000     0.000         5\n",
      "           1      0.511     0.706     0.593        34\n",
      "           2      0.480     0.375     0.421        32\n",
      "           3      0.447     0.340     0.386        50\n",
      "           4      0.174     0.103     0.129        39\n",
      "           5      0.186     0.191     0.188        68\n",
      "           6      0.214     0.091     0.128        33\n",
      "           7      0.000     0.000     0.000        39\n",
      "           8      0.167     0.312     0.217        64\n",
      "           9      0.292     0.253     0.271        75\n",
      "          10      0.184     0.132     0.154        53\n",
      "          11      0.392     0.706     0.504       163\n",
      "          12      0.500     0.043     0.080        23\n",
      "          13      0.128     0.125     0.127        40\n",
      "          14      0.275     0.141     0.186        78\n",
      "          15      0.267     0.098     0.143        41\n",
      "          16      0.646     0.646     0.646        48\n",
      "\n",
      "    accuracy                          0.323       885\n",
      "   macro avg      0.286     0.251     0.246       885\n",
      "weighted avg      0.303     0.323     0.291       885\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "\n",
    "# Assuming X_train, X_test, y_train, y_test are already defined\n",
    "# Apply StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Apply BorderlineSMOTE\n",
    "borderline_smote = BorderlineSMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = borderline_smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "# Define the parameter grid for SVM\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'gamma': [1, 0.1, 0.01, 0.001],\n",
    "}\n",
    "\n",
    "# Initialize the SVM classifier\n",
    "svm_classifier = SVC()\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=svm_classifier,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,  # 5-fold cross-validation\n",
    "    verbose=2,\n",
    "    n_jobs=-1  # Use all available cores\n",
    ")\n",
    "\n",
    "# Fit GridSearchCV\n",
    "grid_search.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Get the best model\n",
    "best_svm_classifier = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on the test set using the best model\n",
    "y_pred_best_svm = best_svm_classifier.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the best model\n",
    "accuracy_best_svm = accuracy_score(y_test, y_pred_best_svm)\n",
    "classification_report_result_best_svm = classification_report(y_test, y_pred_best_svm, digits=3)\n",
    "\n",
    "# Print results\n",
    "print(f\"Best Parameters (SVM with BorderlineSMOTE): {grid_search.best_params_}\")\n",
    "print(f\"Accuracy (SVM with BorderlineSMOTE): {accuracy_best_svm}\")\n",
    "print(\"Classification Report (SVM with BorderlineSMOTE):\\n\", classification_report_result_best_svm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['best_svm.joblib']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model to a file\n",
    "joblib_file = \"best_svm.joblib\"\n",
    "joblib.dump(best_svm_classifier, joblib_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "Best Parameters (Logistic Regression with BorderlineSMOTE): {'C': 100, 'solver': 'liblinear'}\n",
      "Accuracy (Logistic Regression with BorderlineSMOTE): 0.3423728813559322\n",
      "Classification Report (Logistic Regression with BorderlineSMOTE):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0      0.000     0.000     0.000         5\n",
      "           1      0.540     0.794     0.643        34\n",
      "           2      0.571     0.625     0.597        32\n",
      "           3      0.419     0.360     0.387        50\n",
      "           4      0.226     0.308     0.261        39\n",
      "           5      0.224     0.191     0.206        68\n",
      "           6      0.195     0.242     0.216        33\n",
      "           7      0.147     0.128     0.137        39\n",
      "           8      0.163     0.125     0.142        64\n",
      "           9      0.304     0.280     0.292        75\n",
      "          10      0.164     0.208     0.183        53\n",
      "          11      0.610     0.546     0.576       163\n",
      "          12      0.125     0.174     0.145        23\n",
      "          13      0.097     0.150     0.118        40\n",
      "          14      0.321     0.218     0.260        78\n",
      "          15      0.213     0.244     0.227        41\n",
      "          16      0.739     0.708     0.723        48\n",
      "\n",
      "    accuracy                          0.342       885\n",
      "   macro avg      0.298     0.312     0.301       885\n",
      "weighted avg      0.352     0.342     0.343       885\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\python\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\python\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "\n",
    "# Assuming X_train, X_test, y_train, y_test are already defined\n",
    "# Apply StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Apply BorderlineSMOTE\n",
    "smote = BorderlineSMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "# Define the parameter grid for Logistic Regression\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'solver': ['lbfgs', 'liblinear'],  # Choose either 'lbfgs' or 'liblinear' solver\n",
    "}\n",
    "\n",
    "# Initialize the Logistic Regression classifier\n",
    "lr_classifier = LogisticRegression(max_iter=1000)  # Increase max_iter if necessary\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=lr_classifier,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,  # 5-fold cross-validation\n",
    "    verbose=2,\n",
    "    n_jobs=-1  # Use all available cores\n",
    ")\n",
    "\n",
    "# Fit GridSearchCV\n",
    "grid_search.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Get the best model\n",
    "best_lr_classifier = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on the test set using the best model\n",
    "y_pred_best_lr = best_lr_classifier.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the best model\n",
    "accuracy_best_lr = accuracy_score(y_test, y_pred_best_lr)\n",
    "classification_report_result_best_lr = classification_report(y_test, y_pred_best_lr, digits=3)\n",
    "\n",
    "# Print results\n",
    "print(f\"Best Parameters (Logistic Regression with BorderlineSMOTE): {grid_search.best_params_}\")\n",
    "print(f\"Accuracy (Logistic Regression with BorderlineSMOTE): {accuracy_best_lr}\")\n",
    "print(\"Classification Report (Logistic Regression with BorderlineSMOTE):\\n\", classification_report_result_best_lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['best_lr.joblib']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib_file = \"best_lr.joblib\"\n",
    "joblib.dump(best_lr_classifier, joblib_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "Best Parameters (XGBoost with SMOTE): {'gamma': None, 'max_depth': None}\n",
      "Accuracy (XGBoost with SMOTE): 0.34350282485875705\n",
      "Classification Report (XGBoost with SMOTE):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0      0.000     0.000     0.000         5\n",
      "           1      0.492     0.941     0.646        34\n",
      "           2      0.465     0.625     0.533        32\n",
      "           3      0.292     0.380     0.330        50\n",
      "           4      0.231     0.231     0.231        39\n",
      "           5      0.204     0.162     0.180        68\n",
      "           6      0.208     0.152     0.175        33\n",
      "           7      0.235     0.103     0.143        39\n",
      "           8      0.205     0.266     0.231        64\n",
      "           9      0.338     0.347     0.342        75\n",
      "          10      0.189     0.189     0.189        53\n",
      "          11      0.554     0.595     0.574       163\n",
      "          12      0.167     0.043     0.069        23\n",
      "          13      0.041     0.050     0.045        40\n",
      "          14      0.333     0.205     0.254        78\n",
      "          15      0.121     0.098     0.108        41\n",
      "          16      0.585     0.646     0.614        48\n",
      "\n",
      "    accuracy                          0.344       885\n",
      "   macro avg      0.274     0.296     0.274       885\n",
      "weighted avg      0.326     0.344     0.327       885\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')  # Ignore warnings for simplicity\n",
    "\n",
    "# Define the parameter grid for XGBoost\n",
    "param_grid = {\n",
    "    'max_depth': [2, 3, 4, 5, None],\n",
    "    'gamma': [0.1, 0.2, 0.3, 0.4, 0.5, None],\n",
    "}\n",
    "\n",
    "# Initialize the XGBoost classifier\n",
    "xgb_classifier = XGBClassifier(random_state=42)\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=xgb_classifier,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,  # 5-fold cross-validation\n",
    "    verbose=2,\n",
    "    n_jobs=-1  # Use all available cores\n",
    ")\n",
    "\n",
    "# Fit GridSearchCV\n",
    "grid_search.fit(X_train_resampled_borderline, y_train_resampled_borderline)\n",
    "\n",
    "# Get the best model\n",
    "best_xgb_classifier = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on the test set using the best model\n",
    "y_pred_best_xgb = best_xgb_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the best model\n",
    "accuracy_best_xgb = accuracy_score(y_test, y_pred_best_xgb)\n",
    "classification_report_result_best_xgb = classification_report(y_test, y_pred_best_xgb, digits=3)\n",
    "\n",
    "# Print results\n",
    "print(f\"Best Parameters (XGBoost with SMOTE): {grid_search.best_params_}\")\n",
    "print(f\"Accuracy (XGBoost with SMOTE): {accuracy_best_xgb}\")\n",
    "print(\"Classification Report (XGBoost with SMOTE):\\n\", classification_report_result_best_xgb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['best_xgb.joblib']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model to a file\n",
    "joblib_file = \"best_xgb.joblib\"\n",
    "joblib.dump(best_xgb_classifier, joblib_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Best Parameters (AdaBoost with SMOTE): {'learning_rate': 0.1, 'n_estimators': 200}\n",
      "Accuracy (AdaBoost with SMOTE): 0.17627118644067796\n",
      "Classification Report (AdaBoost with SMOTE):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0      0.000     0.000     0.000         5\n",
      "           1      0.353     0.353     0.353        34\n",
      "           2      0.515     0.531     0.523        32\n",
      "           3      0.383     0.460     0.418        50\n",
      "           4      0.060     0.103     0.075        39\n",
      "           5      0.286     0.088     0.135        68\n",
      "           6      0.097     0.091     0.094        33\n",
      "           7      0.080     0.051     0.062        39\n",
      "           8      0.067     0.062     0.065        64\n",
      "           9      0.137     0.173     0.153        75\n",
      "          10      0.121     0.132     0.126        53\n",
      "          11      0.517     0.092     0.156       163\n",
      "          12      0.051     0.261     0.085        23\n",
      "          13      0.117     0.175     0.140        40\n",
      "          14      0.235     0.051     0.084        78\n",
      "          15      0.098     0.317     0.150        41\n",
      "          16      0.444     0.417     0.430        48\n",
      "\n",
      "    accuracy                          0.176       885\n",
      "   macro avg      0.209     0.198     0.179       885\n",
      "weighted avg      0.260     0.176     0.176       885\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')  # Ignore warnings for simplicity\n",
    "\n",
    "\n",
    "# Define the parameter grid for AdaBoost\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150, 200],\n",
    "    'learning_rate': [0.001, 0.1, 1],\n",
    "}\n",
    "\n",
    "# Initialize the AdaBoost classifier\n",
    "ada_classifier = AdaBoostClassifier(random_state=42)\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=ada_classifier,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,  # 5-fold cross-validation\n",
    "    verbose=2,\n",
    "    n_jobs=-1  # Use all available cores\n",
    ")\n",
    "\n",
    "# Fit GridSearchCV on resampled data\n",
    "grid_search.fit(X_train_resampled_borderline, y_train_resampled_borderline)\n",
    "\n",
    "# Get the best model\n",
    "best_ada_classifier = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on the test set using the best model\n",
    "y_pred_best_ada = best_ada_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the best model\n",
    "accuracy_best_ada = accuracy_score(y_test, y_pred_best_ada)\n",
    "classification_report_result_best_ada = classification_report(y_test, y_pred_best_ada, digits=3)\n",
    "\n",
    "# Print results\n",
    "print(f\"Best Parameters (AdaBoost with SMOTE): {grid_search.best_params_}\")\n",
    "print(f\"Accuracy (AdaBoost with SMOTE): {accuracy_best_ada}\")\n",
    "print(\"Classification Report (AdaBoost with SMOTE):\\n\", classification_report_result_best_ada)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['best_ada.joblib']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "# Save the model to a file\n",
    "joblib_file = \"best_ada.joblib\"\n",
    "joblib.dump(best_ada_classifier, joblib_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.086178 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 97920\n",
      "[LightGBM] [Info] Number of data points in the train set: 9655, number of used features: 384\n",
      "[LightGBM] [Info] Start training from score -7.229321\n",
      "[LightGBM] [Info] Start training from score -2.773314\n",
      "[LightGBM] [Info] Start training from score -2.773314\n",
      "[LightGBM] [Info] Start training from score -2.773314\n",
      "[LightGBM] [Info] Start training from score -2.773314\n",
      "[LightGBM] [Info] Start training from score -2.773314\n",
      "[LightGBM] [Info] Start training from score -2.773314\n",
      "[LightGBM] [Info] Start training from score -2.773314\n",
      "[LightGBM] [Info] Start training from score -2.773314\n",
      "[LightGBM] [Info] Start training from score -2.773314\n",
      "[LightGBM] [Info] Start training from score -2.773314\n",
      "[LightGBM] [Info] Start training from score -2.773314\n",
      "[LightGBM] [Info] Start training from score -2.773314\n",
      "[LightGBM] [Info] Start training from score -2.773314\n",
      "[LightGBM] [Info] Start training from score -2.773314\n",
      "[LightGBM] [Info] Start training from score -2.773314\n",
      "[LightGBM] [Info] Start training from score -2.773314\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Best Parameters (LGBM with SMOTE): {'max_depth': -1, 'n_estimators': 50}\n",
      "Accuracy (LGBM with SMOTE): 0.33785310734463275\n",
      "Classification Report (LGBM with SMOTE):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0      0.000     0.000     0.000         5\n",
      "           1      0.467     0.824     0.596        34\n",
      "           2      0.514     0.562     0.537        32\n",
      "           3      0.288     0.340     0.312        50\n",
      "           4      0.278     0.256     0.267        39\n",
      "           5      0.169     0.176     0.173        68\n",
      "           6      0.143     0.061     0.085        33\n",
      "           7      0.143     0.051     0.075        39\n",
      "           8      0.186     0.250     0.213        64\n",
      "           9      0.267     0.320     0.291        75\n",
      "          10      0.292     0.264     0.277        53\n",
      "          11      0.519     0.595     0.554       163\n",
      "          12      0.167     0.043     0.069        23\n",
      "          13      0.122     0.150     0.135        40\n",
      "          14      0.348     0.205     0.258        78\n",
      "          15      0.179     0.122     0.145        41\n",
      "          16      0.564     0.646     0.602        48\n",
      "\n",
      "    accuracy                          0.338       885\n",
      "   macro avg      0.273     0.286     0.270       885\n",
      "weighted avg      0.318     0.338     0.320       885\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')  # Ignore warnings for simplicity\n",
    "\n",
    "# Define the parameter grid for LGBM\n",
    "param_grid = {\n",
    "    'max_depth': [-1, 2, 3, 4, 5],\n",
    "    'n_estimators': [50, 100, 150, 200],\n",
    "}\n",
    "\n",
    "# Initialize the LGBM classifier\n",
    "lgbm_classifier = LGBMClassifier(random_state=42)\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=lgbm_classifier,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,  # 5-fold cross-validation\n",
    "    verbose=2,\n",
    "    n_jobs=-1  # Use all available cores\n",
    ")\n",
    "\n",
    "# Assuming X_train_resampled_smote, y_train_resampled_smote are defined\n",
    "# Fit GridSearchCV on SMOTE resampled data\n",
    "grid_search.fit(X_train_resampled_borderline, y_train_resampled_borderline)\n",
    "\n",
    "# Get the best model\n",
    "best_lgbm_classifier = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on the test set using the best model\n",
    "y_pred_best_lgbm = best_lgbm_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the best model\n",
    "accuracy_best_lgbm = accuracy_score(y_test, y_pred_best_lgbm)\n",
    "classification_report_result_best_lgbm = classification_report(y_test, y_pred_best_lgbm, digits=3)\n",
    "\n",
    "# Print results\n",
    "print(f\"Best Parameters (LGBM with SMOTE): {grid_search.best_params_}\")\n",
    "print(f\"Accuracy (LGBM with SMOTE): {accuracy_best_lgbm}\")\n",
    "print(\"Classification Report (LGBM with SMOTE):\\n\", classification_report_result_best_lgbm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['best_lgbm_classifierMpnet.joblib']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib_file = \"best_lgbm_classifierMpnet.joblib\"\n",
    "joblib.dump(best_lgbm_classifier, joblib_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
